{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3f6e09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17843,
     "status": "ok",
     "timestamp": 1741081612834,
     "user": {
      "displayName": "CLEMENTE ESQUINAS COVES",
      "userId": "18187455758607316569"
     },
     "user_tz": -60
    },
    "id": "iPy08A2FFdUA",
    "outputId": "ca22053c-2bbc-4345-9fa8-010e8f87f567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (1.11.4)\n",
      "Collecting ttml\n",
      "  Downloading ttml-1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (3.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (1.11.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (4.65.0)\n",
      "Requirement already satisfied: autoray in /opt/anaconda3/lib/python3.11/site-packages (from ttml) (0.7.0)\n",
      "Collecting xgboost (from ttml)\n",
      "  Downloading xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/clementeesquinascoves/.local/lib/python3.11/site-packages (from pandas->ttml) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->ttml) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas->ttml) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->ttml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn->ttml) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/clementeesquinascoves/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ttml) (1.17.0)\n",
      "Downloading ttml-1.0-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-3.0.0-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost, ttml\n",
      "Successfully installed ttml-1.0 xgboost-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy\n",
    "!pip install ttml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556c430a",
   "metadata": {
    "id": "oeEssnuZBDN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix F_10 of size 11x11:\n",
      "[[ 5.00000000e-02  1.00000000e-01  9.51056516e-02  8.09016994e-02\n",
      "   5.87785252e-02  3.09016994e-02  6.12323400e-18 -3.09016994e-02\n",
      "  -5.87785252e-02 -8.09016994e-02  5.00000000e-02]\n",
      " [ 1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
      "   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n",
      "   1.00000000e-01  1.00000000e-01  1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01  9.51056516e-02  8.09016994e-02\n",
      "   5.87785252e-02  3.09016994e-02  6.12323400e-18 -3.09016994e-02\n",
      "  -5.87785252e-02 -8.09016994e-02 -1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01  8.09016994e-02  3.09016994e-02\n",
      "  -3.09016994e-02 -8.09016994e-02 -1.00000000e-01 -8.09016994e-02\n",
      "  -3.09016994e-02  3.09016994e-02  1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01  5.87785252e-02 -3.09016994e-02\n",
      "  -9.51056516e-02 -8.09016994e-02 -1.83697020e-17  8.09016994e-02\n",
      "   9.51056516e-02  3.09016994e-02 -1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01  3.09016994e-02 -8.09016994e-02\n",
      "  -8.09016994e-02  3.09016994e-02  1.00000000e-01  3.09016994e-02\n",
      "  -8.09016994e-02 -8.09016994e-02  1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01  6.12323400e-18 -1.00000000e-01\n",
      "  -1.83697020e-17  1.00000000e-01  3.06161700e-17 -1.00000000e-01\n",
      "  -4.28626380e-17  1.00000000e-01 -1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01 -3.09016994e-02 -8.09016994e-02\n",
      "   8.09016994e-02  3.09016994e-02 -1.00000000e-01  3.09016994e-02\n",
      "   8.09016994e-02 -8.09016994e-02  1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01 -5.87785252e-02 -3.09016994e-02\n",
      "   9.51056516e-02 -8.09016994e-02 -4.28626380e-17  8.09016994e-02\n",
      "  -9.51056516e-02  3.09016994e-02 -1.00000000e-01]\n",
      " [ 1.00000000e-01  1.00000000e-01 -8.09016994e-02  3.09016994e-02\n",
      "   3.09016994e-02 -8.09016994e-02  1.00000000e-01 -8.09016994e-02\n",
      "   3.09016994e-02  3.09016994e-02  1.00000000e-01]\n",
      " [ 5.00000000e-02  1.00000000e-01 -1.00000000e-01  1.00000000e-01\n",
      "  -1.00000000e-01  1.00000000e-01 -1.00000000e-01  1.00000000e-01\n",
      "  -1.00000000e-01  1.00000000e-01  5.00000000e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_Fn(n):\n",
    "    \"\"\"\n",
    "    Generates the matrix Fn of size (n+1) x (n+1) according to equation (11).\n",
    "\n",
    "    Args:\n",
    "        n (int): Parameter n1, which determines the size of the matrix (n+1) x (n+1).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The matrix Fn of size (n+1) x (n+1).\n",
    "    \"\"\"\n",
    "    size = n + 1\n",
    "    F = np.zeros((size, size))\n",
    "\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if i == 0 and j == 0:\n",
    "                F[i, j] = 1/4  # Top-left corner\n",
    "            elif i == 0 and j == size - 1:\n",
    "                F[i, j] = 1/4  # Top-right corner\n",
    "            elif i == size - 1 and j == 0:\n",
    "                F[i, j] = 1/4  # Bottom-left corner\n",
    "            elif i == size - 1 and j == size - 1:\n",
    "                F[i, j] = 1/4 * np.cos(np.pi * n)  # Bottom-right corner\n",
    "            elif i == 0:  # First row (except corners)\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * (j - 1) / n)\n",
    "            elif j == 0:  # First column (except corners)\n",
    "                F[i, j] = 1/2\n",
    "            elif j == size - 1:  # Last column (except corners)\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * (i - 1))\n",
    "            elif i == size - 1:  # Last row (except corners)\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * (j - 1))\n",
    "            else:  # Inner elements\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * (i - 1) * (j - 1) / n)\n",
    "\n",
    "    F = (2 / n) * F\n",
    "    return F\n",
    "\n",
    "# Example\n",
    "if __name__ == \"__main__\":\n",
    "    n = 10\n",
    "    F_matrix = generate_Fn(n)\n",
    "\n",
    "    print(f\"Matrix F_{n} of size {(n+1)}x{(n+1)}:\")\n",
    "    print(F_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f7570",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a1468",
   "metadata": {},
   "source": [
    "# Tensor Train Format (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61a3ce8",
   "metadata": {},
   "source": [
    "We consider a general tensor $\\mathcal{X} \\in \\mathbb{R}^{n_1 \\times \\dots \\times n_d}$ of order $d$.\n",
    "\n",
    "The TT-ranks of $\\mathcal{X}$ form a tuple of integers:\n",
    "\n",
    "$$\\text{rank}_{\\text{TT}} = (r_0, \\dots, r_d) := (1, \\text{rank}(X^{<1>}), \\dots, \\text{rank}(X^{}), 1)$$\n",
    "\n",
    "Each entry of the tensor $\\mathcal{X}(i_1, \\dots, i_d)$ can be expressed as a product of $d$ matrices:\n",
    "\n",
    "$$\\mathcal{X}(i_1,\\dots,i_d) = U_1(i_1) U_2(i_2) \\dots U_d(i_d)$$\n",
    "\n",
    "where $U_\\mu(i_\\mu)$ is a matrix of size $r_{\\mu-1} \\times r_\\mu$. For each $\\mu = 1,\\dots,d$, the $n_\\mu$ matrices $U_\\mu(i_\\mu)$ for $i_\\mu = 1,\\dots,n_\\mu$ can be grouped into a 3rd-order tensor $\\mathbf{U}\\mu$ of shape $r{\\mu-1} \\times n_\\mu \\times r_\\mu$. These are called TT-cores, and by construction we have:\n",
    "\n",
    "$$\\mathcal{X}(i_1,\\dots,i_d) = \\sum_{k_1=1}^{r_1} \\dots \\sum_{k_{d-1}=1}^{r_{d-1}} \\mathbf{U}_1(1,i_1,k_1) \\mathbf{U}_2(k_1,i_2,k_2) \\dots \\mathbf{U}d(k{d-1},i_d,1)$$\n",
    "\n",
    "We have a tensor $\\mathcal{X} \\in \\mathbb{R}^{n_1 \\times \\dots \\times n_d}$ in Tensor Train format, which consists of $d$ cores $U_1, \\dots, U_d$, where each core $U_k$ corresponds to the $k$-th dimension.\n",
    "\n",
    "The core $U_k$ for $k = 1,\\dots,d$ has shape $(r_{k-1}, n_k, r_k)$, where:\n",
    "\t•\t$r_{k-1}$: TT-rank connecting to the previous core (for $k=1$, $r_0=1$),\n",
    "\t•\t$n_k$: Size of the $k$-th dimension of the original tensor,\n",
    "\t•\t$r_k$: TT-rank connecting to the next core (for $k=d$, $r_d=1$).\n",
    "\n",
    "Example: If $\\mathcal{X}$ has:\n",
    "\t•\tDimensions $n = [n_1, n_2, n_3] = [4, 5, 6]$\n",
    "\t•\tTT-ranks $r = [1, 3, 3, 1]$\n",
    "\n",
    "Then the TT-cores are:\n",
    "\t•\t$U_1$: shape $(1, 4, 3)$\n",
    "\t•\t$U_2$: shape $(3, 5, 3)$\n",
    "\t•\t$U_3$: shape $(3, 6, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a267bc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e97ac",
   "metadata": {},
   "source": [
    "# Mode-$\\mu$ Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a89da",
   "metadata": {},
   "source": [
    "The mode-$\\mu$ product of a tensor $\\mathcal{X} \\in \\mathbb{R}^{n_1 \\times \\dots \\times n_d}$ with a matrix $M \\in \\mathbb{R}^{m \\times n_\\mu}$ is defined as:\n",
    "\n",
    "$$ \\mathcal{Z}(i_1,\\dots,i_{\\mu-1},j,i_{\\mu+1},\\dots,i_d) = \\sum_{i_\\mu=1}^{n_\\mu} \\mathcal{X}(i_1,\\dots,i_d) M(j,i_\\mu), \\quad j = 1, \\dots, m $$\n",
    "\n",
    "This operation is denoted by $\\mathcal{Z} = \\mathcal{X} \\times_\\mu M$. The resulting tensor $\\mathcal{Z} \\in \\mathbb{R}^{n_1 \\times \\dots \\times n_{\\mu-1} \\times m \\times n_{\\mu+1} \\times \\dots \\times n_d}$.\n",
    "\n",
    "This means that the matrix $M$ “acts” on the $\\mu$-th mode of the tensor, replacing its dimension $n_\\mu$ with $m$ (the number of rows in $M$), while leaving the other dimensions unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6543cd7a",
   "metadata": {},
   "source": [
    "In our case, we will use mode-$\\mu$ matrix multiplication to compute the product $\\mathcal{P} \\times_1 F_n$, where $F_n \\in \\mathbb{R}^{(n+1) \\times (n+1)}$ and $\\mathcal{P}$ is the tensor resulting from tensor completion, represented in TT format.\n",
    "\n",
    "This operation is performed with the goal of obtaining the tensor $\\mathcal{C}$ of Chebyshev interpolation coefficients. In our specific case ($\\mu = 1$):\n",
    "\t•\t$\\mathcal{P} \\in \\mathbb{R}^{n_1 \\times \\dots \\times n_d}$ is the tensor in TT format.\n",
    "\t•\t$F_{n_1} \\in \\mathbb{R}^{m \\times n_1}$ is the matrix generated by the function above.\n",
    "\t•\tThe result $\\mathcal{Z} = \\mathcal{P} \\times_1 F_{n_1}$ is a tensor\n",
    "$\\mathcal{Z} \\in \\mathbb{R}^{m \\times n_2 \\times \\dots \\times n_d}$.\n",
    "\t•\tThe mode-1 multiplication is defined as:\n",
    "\n",
    "$$\n",
    "\\mathcal{Z}(j,i_2,\\dots,i_d) = \\sum_{i_1=1}^{n_1} \\mathcal{P}(i_1,i_2,\\dots,i_d) \\cdot F_n(j,i_1), \\quad j=1,\\dots,m\n",
    "$$\n",
    "\n",
    "Note: This is the definition in the dense case. What it does is transform the first dimension of $\\mathcal{P}$ from size $n_1$ to $m$, as if $F_{n_1}$ were multiplying each mode-1 “fiber” of $\\mathcal{P}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55e221",
   "metadata": {},
   "source": [
    "**Application: Mode-1 Matrix Multiplication in TT Format**\n",
    "\n",
    "When multiplying $\\mathcal{P}$ by $F_{n_1}$ along mode-1, we aim to obtain $\\mathcal{Z}$ in TT format. This operation affects only the first dimension, represented by the first core $\\mathbf{U}_1$ (a 3rd-order tensor).\n",
    "\n",
    "So we modify only $\\mathbf{U}_1$ while keeping the other TT-cores unchanged.\n",
    "\t•\t$\\mathbf{U}_1$ has shape $(1, n_1, r_1)$\n",
    "\t•\t$F_{n_1}$ has shape $(m, n_1)$\n",
    "\t•\tThe new TT-core will have shape $(1, m, r_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179b528",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859ad42",
   "metadata": {},
   "source": [
    "In order for the algorithm to work properly, we must assume that\n",
    "$\\mathcal{P} \\in \\mathbb{R}^{(n_1+1) \\times (n_2+1) \\times \\dots \\times (n_d+1)}$.\n",
    "This ensures that we can apply mode-2 matrix multiplication of each TT-core $\\mathbf{U}\\mu$ of $\\mathcal{P}$ by the matrix $F{n_\\mu} \\in \\mathbb{R}^{(n_\\mu+1) \\times (n_\\mu+1)}$ without issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afae1d74",
   "metadata": {
    "id": "28_FIqDuQNTJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mode_mu_multiply(X, M, mu):\n",
    "    \"\"\"\n",
    "    Performs mode-μ multiplication between a tensor X and a matrix M.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Input tensor of shape (n_1, ..., n_d).\n",
    "        M (numpy.ndarray): Matrix of shape (m, n_mu), where n_mu is the size of the μ-th dimension.\n",
    "        mu (int): Index of the dimension for multiplication (1-based, internally adjusted to 0-based).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Resulting tensor Z of shape (n_1, ..., n_{mu-1}, m, n_{mu+1}, ..., n_d).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If mu is out of bounds or M's dimensions do not match n_mu.\n",
    "    \"\"\"\n",
    "    dims = X.shape\n",
    "    d = len(dims)\n",
    "\n",
    "    if mu < 1 or mu > d:\n",
    "        raise ValueError(f\"mu must be between 1 and {d}\")\n",
    "    mu -= 1\n",
    "\n",
    "    n_mu = dims[mu]\n",
    "    m, n_mu_M = M.shape\n",
    "    if n_mu_M != n_mu:\n",
    "        raise ValueError(f\"Second dimension of M ({n_mu_M}) must match n_{mu+1} ({n_mu})\")\n",
    "\n",
    "    new_dims = list(dims)\n",
    "    new_dims[mu] = m\n",
    "\n",
    "    # Permute to move mu-th axis to the end\n",
    "    axes_order = list(range(d))\n",
    "    axes_order.pop(mu)\n",
    "    axes_order.append(mu)\n",
    "    X_permuted = np.transpose(X, axes_order)\n",
    "\n",
    "    # Reshape to matrix\n",
    "    X_mat = X_permuted.reshape(-1, n_mu)\n",
    "\n",
    "    # Matrix multiplication\n",
    "    Z_mat = np.dot(X_mat, M.T)\n",
    "\n",
    "    # Reshape back to tensor\n",
    "    Z_permuted = Z_mat.reshape(*new_dims[0:mu], m, *new_dims[mu+1:])\n",
    "    inverse_axes = list(range(mu)) + [d-1] + list(range(mu, d-1))\n",
    "    Z = np.transpose(Z_permuted, axes=inverse_axes)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e7c6d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741081612840,
     "user": {
      "displayName": "CLEMENTE ESQUINAS COVES",
      "userId": "18187455758607316569"
     },
     "user_tz": -60
    },
    "id": "wlx_2_icQPyW",
    "outputId": "2b054d53-8d34-494a-9639-737d7da1f354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (4, 5, 3)\n",
      "Shape of M: (3, 5)\n",
      "Shape of Z: (4, 3, 3)\n",
      "First elements of Z:\n",
      " [[[0.19220043 0.72448725]\n",
      "  [0.59425929 1.16160491]]\n",
      "\n",
      " [[1.02139197 1.38547352]\n",
      "  [1.71538183 1.35754243]]]\n"
     ]
    }
   ],
   "source": [
    "# Example of usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a sample 3D tensor X\n",
    "    n1, n2, n3 = 4, 5, 3  # Dimensions: (n_1, n_2, n_3)\n",
    "    X = np.random.rand(n1, n2, n3)  # Random tensor of shape (4, 5, 3)\n",
    "\n",
    "    # Create a matrix M to multiply along mode mu=2\n",
    "    m = 3  # New dimension replacing n_2\n",
    "    M = np.random.rand(m, n2)  # Matrix of shape (m, n_2) = (3, 5)\n",
    "    mu = 2  # Mode-2 multiplication (1-based index)\n",
    "\n",
    "    # Perform the mode-μ multiplication\n",
    "    Z = mode_mu_multiply(X, M, mu)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Shape of X:\", X.shape)  # Should be (4, 5, 3)\n",
    "    print(\"Shape of M:\", M.shape)  # Should be (3, 5)\n",
    "    print(\"Shape of Z:\", Z.shape)  # Should be (4, 3, 3)\n",
    "    print(\"First elements of Z:\\n\", Z[:2, :2, :2])  # Show a small slice of Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d9990",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a4117",
   "metadata": {},
   "source": [
    "If the tensor $\\mathcal{X}$ is in Tensor Train (TT) decomposition, then it is straightforward to obtain a TT decomposition of $\\mathcal{Z}$ by performing a mode-2 matrix multiplication of the TT-core $\\mathbf{U}_\\mu$ with $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e338a53",
   "metadata": {
    "id": "CmuAM1CpuJje"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ttml.tensor_train import TensorTrain\n",
    "\n",
    "# Assuming the function mode_mu_multiply is already defined\n",
    "def mode_mu_multiply(X, M, mu):\n",
    "    \"\"\"\n",
    "    Performs mode-μ matrix multiplication between a dense tensor X and a matrix M.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Input tensor of shape (n_1, ..., n_d).\n",
    "        M (numpy.ndarray): Matrix of shape (m, n_mu), where n_mu is the size of the mu-th dimension.\n",
    "        mu (int): Index of the dimension for multiplication (1-based, internally adjusted to 0-based).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Resulting tensor Z of shape (n_1, ..., n_{mu-1}, m, n_{mu+1}, ..., n_d).\n",
    "    \"\"\"\n",
    "    dims = X.shape  # (n_1, n_2, ..., n_d)\n",
    "    d = len(dims)   # Number of dimensions\n",
    "\n",
    "    # Adjust mu to 0-based index\n",
    "    if mu < 1 or mu > d:\n",
    "        raise ValueError(f\"mu must be between 1 and {d}\")\n",
    "    mu -= 1\n",
    "\n",
    "    # Check that second dimension of M matches n_mu\n",
    "    n_mu = dims[mu]\n",
    "    m, n_mu_M = M.shape\n",
    "    if n_mu_M != n_mu:\n",
    "        raise ValueError(f\"The second dimension of M ({n_mu_M}) must match n_{mu+1} ({n_mu})\")\n",
    "\n",
    "    # Create the new shape for Z\n",
    "    new_dims = list(dims)\n",
    "    new_dims[mu] = m  # Replace n_mu with m in dimension mu\n",
    "\n",
    "    # Permute X to move the mu-th dimension to the last position\n",
    "    axes_order = list(range(d))\n",
    "    axes_order.pop(mu)\n",
    "    axes_order.append(mu)\n",
    "    X_permuted = np.transpose(X, axes_order)\n",
    "\n",
    "    # Reshape X for matrix multiplication\n",
    "    X_mat = X_permuted.reshape(-1, n_mu)\n",
    "\n",
    "    # Perform matrix multiplication: Z_mat shape will be (product of other dims × m)\n",
    "    Z_mat = np.dot(X_mat, M.T)  # M.T because we want M(j, i_mu), not M(i_mu, j)\n",
    "\n",
    "    # Reshape Z_mat back to tensor shape\n",
    "    Z_permuted = Z_mat.reshape(*new_dims[0:mu], m, *new_dims[mu+1:])\n",
    "\n",
    "    # Restore original axis order\n",
    "    inverse_axes = list(range(mu)) + [d - 1] + list(range(mu, d - 1))\n",
    "    Z = np.transpose(Z_permuted, axes=inverse_axes)\n",
    "\n",
    "    return Z\n",
    "\n",
    "def mode_mu_tt_multiply(P, F_n_mu, mu):\n",
    "    \"\"\"\n",
    "    Performs mode-μ multiplication between a TT tensor P and a matrix F_n_mu,\n",
    "    using mode_mu_multiply on the TT cores and returning Z in TT format.\n",
    "\n",
    "    Args:\n",
    "        P (TensorTrain): TT-format tensor with dimensions [(n_1+1), ..., (n_d+1)].\n",
    "        F_n_mu (numpy.ndarray): Matrix of shape (n_mu + 1, n_mu + 1).\n",
    "        mu (int): Index of the dimension for multiplication (1-based).\n",
    "\n",
    "    Returns:\n",
    "        TensorTrain: Resulting TT tensor Z = P ×_mu F_n_mu.\n",
    "    \"\"\"\n",
    "    if mu < 1 or mu > len(P.dims):\n",
    "        raise ValueError(f\"mu must be between 1 and {len(P.dims)}\")\n",
    "    mu -= 1\n",
    "\n",
    "    # Check compatibility of matrix dimensions\n",
    "    n_mu_plus_1 = P.dims[mu]\n",
    "    m, n_mu_F = F_n_mu.shape\n",
    "    if n_mu_F != n_mu_plus_1 or m != n_mu_plus_1:\n",
    "        raise ValueError(f\"Dimensions of F_n_mu ({m}x{n_mu_F}) do not match n_mu+1 ({n_mu_plus_1})\")\n",
    "\n",
    "    # Extract TT-core U_mu of shape (r_{mu-1}, n_mu + 1, r_mu)\n",
    "    core_mu = P.cores[mu]\n",
    "    r_prev, n, r_next = core_mu.shape\n",
    "\n",
    "    # Reshape for mode-1 multiplication: (r_prev * n, r_next)\n",
    "    reshaped_core = core_mu.reshape(r_prev * n, r_next)\n",
    "\n",
    "    # Perform dense mode-1 multiplication\n",
    "    temp_tensor_2d = reshaped_core\n",
    "    Z_temp = mode_mu_multiply(temp_tensor_2d, F_n_mu, 1)\n",
    "\n",
    "    # Reshape result to new TT-core: (r_prev, m, r_next)\n",
    "    new_core_mu = Z_temp.reshape(r_prev, m, r_next)\n",
    "\n",
    "    # Replace the mu-th core in the TT\n",
    "    new_cores = [core.copy() for core in P.cores]\n",
    "    new_cores[mu] = new_core_mu\n",
    "\n",
    "    return TensorTrain(new_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31815a4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1741081630933,
     "user": {
      "displayName": "CLEMENTE ESQUINAS COVES",
      "userId": "18187455758607316569"
     },
     "user_tz": -60
    },
    "id": "HOgs0Axhujo0",
    "outputId": "ee711b2b-0141-49ff-c356-0e3c239c824f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions of P: (5, 5, 5)\n",
      "Dimensions of Z: (5, 5, 5)\n",
      "Original TT ranks of P: (3, 3)\n",
      "TT ranks of Z: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Example of usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up an example TT tensor\n",
    "    n = 4  # Base size for each dimension\n",
    "    d = 3  # 3 dimensions\n",
    "    dims = [n + 1] * d  # Dimensions: [5, 5, 5]\n",
    "    initial_rank = 3  # Consistent initial rank\n",
    "\n",
    "    # Create initial TT cores for P\n",
    "    cores = []\n",
    "    for k in range(d):\n",
    "        if k == 0:\n",
    "            cores.append(np.random.rand(1, dims[k], initial_rank))  # (1, 5, 3)\n",
    "        elif k == d - 1:\n",
    "            cores.append(np.random.rand(initial_rank, dims[k], 1))  # (3, 5, 1)\n",
    "        else:\n",
    "            cores.append(np.random.rand(initial_rank, dims[k], initial_rank))  # (3, 5, 3)\n",
    "\n",
    "    P = TensorTrain(cores)\n",
    "\n",
    "    # Generate matrix F_n_mu for mu = 1 (n_mu = n = 4)\n",
    "    mu = 1  # Mode-1\n",
    "    F_n_mu = generate_Fn(n)  # Matrix (n + 1) x (n + 1) = (5, 5)\n",
    "\n",
    "    # Perform mode-1 multiplication\n",
    "    Z = mode_mu_tt_multiply(P, F_n_mu, mu)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Original dimensions of P:\", P.dims)  # [5, 5, 5]\n",
    "    print(\"Dimensions of Z:\", Z.dims)  # [5, 5, 5] (same shape, since F_n_mu is square)\n",
    "    print(\"Original TT ranks of P:\", P.tt_rank)  # [1, 3, 3, 1]\n",
    "    print(\"TT ranks of Z:\", Z.tt_rank)  # Should be [1, 3, 3, 1] or adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f64b10",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e523c",
   "metadata": {},
   "source": [
    "# Algorithm 3. Efficient computation of $\\mathcal{C}$ (TT tensor of Chebyshev interpolation coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776107f",
   "metadata": {},
   "source": [
    "Input: Tensor $\\mathcal{P}$ in TT format, containing the function values on the Chebyshev grid.\n",
    "\n",
    "Output: Tensor (in TT format) $\\mathcal{C} \\in \\mathbb{R}^{(n_1+1)\\times(n_2+1)\\times\\dots\\times(n_d+1)}$, defined by\n",
    "\n",
    "$$\\mathcal{C}(i_1,i_2,\\dots,i_d) = c_{i_1-1,i_2-1,\\dots,i_d-1}$$\n",
    "\n",
    "for $i_j = 1,\\dots,n_j+1$ and $j = 1,\\dots,d$.\n",
    "\n",
    "\t1.\tCompute $F_{n_1}$ using the function generate_Fn.\n",
    "\t2.\t$\\mathcal{C} \\leftarrow \\mathcal{P} \\times_1 F_{n_1}$\n",
    "\t3.\tFor $m = 2,\\dots,d$:\n",
    "  3.1 Compute $F_{n_m}$\n",
    "  3.2 $\\mathcal{C} \\leftarrow \\mathcal{C} \\times_m F_{n_m}$\n",
    "\t4.\tEnd for\n",
    "\n",
    "Important: If $n_1 = \\dots = n_d$ (the usual case), the algorithm simplifies because $F_n$ only needs to be computed once. The specific structure of the matrices $F_{n_i}$ allows for the use of a Fast-Fourier-Transform-based algorithm that computes each mode-$\\mu$ multiplication more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87eb2ffa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1741081630956,
     "user": {
      "displayName": "CLEMENTE ESQUINAS COVES",
      "userId": "18187455758607316569"
     },
     "user_tz": -60
    },
    "id": "8-9YOULasbnA",
    "outputId": "1851f1d5-d621-40bf-d57b-656faa756ba7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of P: (5, 5, 5)\n",
      "Dimensions of C: (5, 5, 5)\n",
      "TT ranks of P: (3, 3)\n",
      "TT ranks of C: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ttml.tensor_train import TensorTrain\n",
    "\n",
    "def mode_mu_multiply(X, M, mu):\n",
    "    \"\"\"\n",
    "    Performs mode-μ multiplication between a dense tensor X and a matrix M.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Input tensor of shape (n_1, ..., n_d).\n",
    "        M (numpy.ndarray): Matrix of shape (m, n_mu).\n",
    "        mu (int): Dimension index (1-based, internally adjusted to 0-based).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Resulting tensor Z.\n",
    "    \"\"\"\n",
    "    dims = X.shape\n",
    "    d = len(dims)\n",
    "    if mu < 1 or mu > d:\n",
    "        raise ValueError(f\"mu must be between 1 and {d}\")\n",
    "    mu -= 1\n",
    "\n",
    "    n_mu = dims[mu]\n",
    "    m, n_mu_M = M.shape\n",
    "    if n_mu_M != n_mu:\n",
    "        raise ValueError(f\"Second dimension of M ({n_mu_M}) must match n_{mu+1} ({n_mu})\")\n",
    "\n",
    "    new_dims = list(dims)\n",
    "    new_dims[mu] = m\n",
    "\n",
    "    axes_order = list(range(d))\n",
    "    axes_order.pop(mu)\n",
    "    axes_order.append(mu)\n",
    "    X_permuted = np.transpose(X, axes_order)\n",
    "\n",
    "    X_mat = X_permuted.reshape(-1, n_mu)\n",
    "    Z_mat = np.dot(X_mat, M.T)\n",
    "\n",
    "    Z_permuted = Z_mat.reshape(*new_dims[0:mu], m, *new_dims[mu+1:])\n",
    "    inverse_axes = list(range(mu)) + [d - 1] + list(range(mu, d - 1))\n",
    "    Z = np.transpose(Z_permuted, axes=inverse_axes)\n",
    "\n",
    "    return Z\n",
    "\n",
    "def mode_mu_tt_multiply(P, F_n_mu, mu):\n",
    "    \"\"\"\n",
    "    Performs mode-μ multiplication between a TT tensor P and a matrix F_n_mu,\n",
    "    using mode_mu_multiply on the cores and returning Z in TT format.\n",
    "\n",
    "    Args:\n",
    "        P (TensorTrain): TT-format tensor with shape [(n_1+1), ..., (n_d+1)].\n",
    "        F_n_mu (numpy.ndarray): Matrix of shape (n_mu + 1, n_mu + 1).\n",
    "        mu (int): Dimension index for multiplication (1-based).\n",
    "\n",
    "    Returns:\n",
    "        TensorTrain: Resulting TT tensor Z = P ×_mu F_n_mu.\n",
    "    \"\"\"\n",
    "    if mu < 1 or mu > len(P.dims):\n",
    "        raise ValueError(f\"mu must be between 1 and {len(P.dims)}\")\n",
    "    mu -= 1\n",
    "\n",
    "    n_mu_plus_1 = P.dims[mu]\n",
    "    m, n_mu_F = F_n_mu.shape\n",
    "    if n_mu_F != n_mu_plus_1 or m != n_mu_plus_1:\n",
    "        raise ValueError(f\"Dimensions of F_n_mu ({m}x{n_mu_F}) do not match n_mu+1 ({n_mu_plus_1})\")\n",
    "\n",
    "    core_mu = P.cores[mu]\n",
    "    r_prev, n, r_next = core_mu.shape\n",
    "\n",
    "    reshaped_core = core_mu.reshape(n, r_prev * r_next)\n",
    "\n",
    "    temp_tensor_2d = reshaped_core\n",
    "    Z_temp = mode_mu_multiply(temp_tensor_2d, F_n_mu, 1)\n",
    "\n",
    "    new_core_mu = Z_temp.reshape(r_prev, m, r_next)\n",
    "\n",
    "    new_cores = [core.copy() for core in P.cores]\n",
    "    new_cores[mu] = new_core_mu\n",
    "\n",
    "    return TensorTrain(new_cores)\n",
    "\n",
    "def generate_Fn(n):\n",
    "    \"\"\"\n",
    "    Generates the matrix Fn of shape (n+1) x (n+1) as defined in equation (11).\n",
    "\n",
    "    Args:\n",
    "        n (int): Parameter ni determining the size of the matrix.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Matrix Fn of shape (n+1) x (n+1).\n",
    "    \"\"\"\n",
    "    size = n + 1\n",
    "    F = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if (i == 0 and j == 0) or (i == n and j == n):\n",
    "                F[i, j] = 1/4\n",
    "            elif i == 0 or i == n or j == 0 or j == n:\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * i * j / n)\n",
    "            else:\n",
    "                F[i, j] = 1/2 * np.cos(np.pi * (i - 1) * (j - 1) / n)\n",
    "    F = (2 / n) * F\n",
    "    return F\n",
    "\n",
    "def compute_C_efficient(P, n, d):\n",
    "    \"\"\"\n",
    "    Implements Algorithm 3 to efficiently compute the Chebyshev coefficient tensor C in TT format,\n",
    "    applying mode-μ multiplications with matrices F_n.\n",
    "\n",
    "    Args:\n",
    "        P (TensorTrain): Initial TT tensor with dimensions [(n+1), ..., (n+1)].\n",
    "        n (int): Base size for each dimension (n_i = n).\n",
    "        d (int): Number of dimensions.\n",
    "\n",
    "    Returns:\n",
    "        TensorTrain: TT tensor C with Chebyshev coefficients.\n",
    "    \"\"\"\n",
    "    F_n1 = generate_Fn(n)\n",
    "    C = mode_mu_tt_multiply(P, F_n1, 1)\n",
    "\n",
    "    for m in range(2, d + 1):\n",
    "        F_nm = generate_Fn(n)\n",
    "        C = mode_mu_tt_multiply(C, F_nm, m)\n",
    "\n",
    "    return C\n",
    "\n",
    "# Example of usage\n",
    "if __name__ == \"__main__\":\n",
    "    n = 4  # Base size for each dimension\n",
    "    d = 3  # 3 dimensions\n",
    "    dims = [n + 1] * d  # [5, 5, 5]\n",
    "    initial_rank = 3\n",
    "\n",
    "    cores = []\n",
    "    for k in range(d):\n",
    "        if k == 0:\n",
    "            cores.append(np.random.rand(1, dims[k], initial_rank))  # (1, 5, 3)\n",
    "        elif k == d - 1:\n",
    "            cores.append(np.random.rand(initial_rank, dims[k], 1))  # (3, 5, 1)\n",
    "        else:\n",
    "            cores.append(np.random.rand(initial_rank, dims[k], initial_rank))  # (3, 5, 3)\n",
    "\n",
    "    P = TensorTrain(cores)\n",
    "    C = compute_C_efficient(P, n, d)\n",
    "\n",
    "    print(\"Dimensions of P:\", P.dims)\n",
    "    print(\"Dimensions of C:\", C.dims)\n",
    "    print(\"TT ranks of P:\", P.tt_rank)\n",
    "    print(\"TT ranks of C:\", C.tt_rank)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNb9e89Hq1GloyZPOvgXMLo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
