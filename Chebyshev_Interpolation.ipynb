{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO96ysbj4R+OriRJkBlAujS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install numpy scipy\n","!pip install ttml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPy08A2FFdUA","executionInfo":{"status":"ok","timestamp":1741081612834,"user_tz":-60,"elapsed":17843,"user":{"displayName":"CLEMENTE ESQUINAS COVES","userId":"18187455758607316569"}},"outputId":"ca22053c-2bbc-4345-9fa8-010e8f87f567"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n","Collecting ttml\n","  Downloading ttml-1.0-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ttml) (1.26.4)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from ttml) (3.4.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ttml) (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from ttml) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ttml) (1.13.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ttml) (4.67.1)\n","Collecting autoray (from ttml)\n","  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from ttml) (2.1.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ttml) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ttml) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ttml) (2025.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ttml) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ttml) (3.5.0)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->ttml) (2.21.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ttml) (1.17.0)\n","Downloading ttml-1.0-py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: autoray, ttml\n","Successfully installed autoray-0.7.0 ttml-1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeEssnuZBDN2"},"outputs":[],"source":["import numpy as np\n","\n","def generate_Fn(n):\n","    \"\"\"\n","    Genera la matriz Fn de tamaño (n+1) x (n+1) según la ecuación (11).\n","\n","    Args:\n","        n (int): El parámetro n1, que determina el tamaño de la matriz (n+1) x (n+1).\n","\n","    Returns:\n","        numpy.ndarray: La matriz Fn de tamaño (n+1) x (n+1).\n","    \"\"\"\n","    # Crear una matriz de ceros con tamaño (n+1) x (n+1)\n","    size = n + 1\n","    F = np.zeros((size, size))\n","\n","    # Llenar la matriz según la estructura de la ecuación (11)\n","    for i in range(size):\n","        for j in range(size):\n","            if i == 0 and j == 0:\n","                F[i, j] = 1/4  # Esquina superior izquierda\n","            elif i == 0 and j == size - 1:\n","                F[i, j] = 1/4  # Esquina superior derecha\n","            elif i == size - 1 and j == 0:\n","                F[i, j] = 1/4  # Esquina inferior izquierda\n","            elif i == size - 1 and j == size - 1:\n","                F[i, j] = 1/4 * np.cos(np.pi * n)  # Esquina inferior derecha\n","            elif i == 0:  # Primera fila (excepto esquinas)\n","                F[i, j] = 1/2 * np.cos(np.pi * (j - 1) / n)\n","            elif j == 0:  # Primera columna (excepto esquinas)\n","                F[i, j] = 1/2\n","            elif j == size - 1:  # Última columna (excepto esquinas)\n","                F[i, j] = 1/2 * np.cos(np.pi * (i - 1))\n","            elif i == size - 1:  # Última fila (excepto esquinas)\n","                F[i, j] = 1/2 * np.cos(np.pi * (j - 1))\n","            else:  # Elementos intermedios\n","                F[i, j] = 1/2 * np.cos(np.pi * (i - 1) * (j - 1) / n)\n","\n","    # Escalar la matriz por 2/n según la ecuación\n","    F = (2 / n) * F\n","\n","    return F"]},{"cell_type":"code","source":["# Ejemplo de uso\n","if __name__ == \"__main__\":\n","    # Probar con n = 4 (por ejemplo)\n","    n = 10\n","    F_matrix = generate_Fn(n)\n","\n","    print(f\"Matriz F_{n} de tamaño {(n+1)}x{(n+1)}:\")\n","    print(F_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT9w8Y0zsgJY","executionInfo":{"status":"ok","timestamp":1740563943553,"user_tz":-60,"elapsed":4,"user":{"displayName":"CLEMENTE ESQUINAS COVES","userId":"18187455758607316569"}},"outputId":"e21dccc3-4348-48d3-ca6a-a312417a0d9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz F_10 de tamaño 11x11:\n","[[ 5.00000000e-02  1.00000000e-01  9.51056516e-02  8.09016994e-02\n","   5.87785252e-02  3.09016994e-02  6.12323400e-18 -3.09016994e-02\n","  -5.87785252e-02 -8.09016994e-02  5.00000000e-02]\n"," [ 1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n","   1.00000000e-01  1.00000000e-01  1.00000000e-01  1.00000000e-01\n","   1.00000000e-01  1.00000000e-01  1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01  9.51056516e-02  8.09016994e-02\n","   5.87785252e-02  3.09016994e-02  6.12323400e-18 -3.09016994e-02\n","  -5.87785252e-02 -8.09016994e-02 -1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01  8.09016994e-02  3.09016994e-02\n","  -3.09016994e-02 -8.09016994e-02 -1.00000000e-01 -8.09016994e-02\n","  -3.09016994e-02  3.09016994e-02  1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01  5.87785252e-02 -3.09016994e-02\n","  -9.51056516e-02 -8.09016994e-02 -1.83697020e-17  8.09016994e-02\n","   9.51056516e-02  3.09016994e-02 -1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01  3.09016994e-02 -8.09016994e-02\n","  -8.09016994e-02  3.09016994e-02  1.00000000e-01  3.09016994e-02\n","  -8.09016994e-02 -8.09016994e-02  1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01  6.12323400e-18 -1.00000000e-01\n","  -1.83697020e-17  1.00000000e-01  3.06161700e-17 -1.00000000e-01\n","  -4.28626380e-17  1.00000000e-01 -1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01 -3.09016994e-02 -8.09016994e-02\n","   8.09016994e-02  3.09016994e-02 -1.00000000e-01  3.09016994e-02\n","   8.09016994e-02 -8.09016994e-02  1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01 -5.87785252e-02 -3.09016994e-02\n","   9.51056516e-02 -8.09016994e-02 -4.28626380e-17  8.09016994e-02\n","  -9.51056516e-02  3.09016994e-02 -1.00000000e-01]\n"," [ 1.00000000e-01  1.00000000e-01 -8.09016994e-02  3.09016994e-02\n","   3.09016994e-02 -8.09016994e-02  1.00000000e-01 -8.09016994e-02\n","   3.09016994e-02  3.09016994e-02  1.00000000e-01]\n"," [ 5.00000000e-02  1.00000000e-01 -1.00000000e-01  1.00000000e-01\n","  -1.00000000e-01  1.00000000e-01 -1.00000000e-01  1.00000000e-01\n","  -1.00000000e-01  1.00000000e-01  5.00000000e-02]]\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"3tD41MLnLuMF"}},{"cell_type":"markdown","source":["# Formato Tensor Train (teoría)"],"metadata":{"id":"7ctKbS5gPh24"}},{"cell_type":"markdown","source":["Consideramos un tensor general $\\mathcal{X}\\in\\mathbb{R}^{n_1\\times\\dots\\times n_d}$ de orden $d$.\n","\n","Los rangos TT de $\\mathcal{X}$ forman una tupla de enteros\n","\n","$$\\text{rank}_{\\text{TT}}=(r_0,\\dots,r_d):=(1,\\text{rank}(X^{<1>}),\\dots,\\text{rank}(X^{<d-1>}),1)$$\n","\n","Cada entrada del tensor $\\mathcal{X}(i_1,\\dots,i_d)$ se puede expresar como un producto de $d$ matrices:\n","\n","$$\\mathcal{X}(i_1,\\dots,i_d)=U_1(i_1)U_2(i_2)\\dots U_d(i_d) $$\n","\n","con $U_\\mu(i_\\mu)$ una matriz de tamaño $r_{\\mu-1}\\times r_\\mu$. Para cada $\\mu=1,\\dots, d$, se pueden agrupar las $n_\\mu$ matrices $U_\\mu(i_\\mu),\\quad i_\\mu=1,\\dots,n_\\mu$ en un tensor de tercer orden $\\mathbf{U}_\\mu$ de tamaño $r_{\\mu-1}\\times n_\\mu \\times r_\\mu$. A estos tensores se les llama cores TT, y por construcción, tenemos:\n","\n","$$\\mathcal{X}(i_1,\\dots,i_d)=\\sum_{k_1=1}^{r_1} \\dots \\sum _{k_{d-1}=1}^{r_{d-1}}\\mathbf{U}_1(1,i_1,k_1)\\mathbf{U}_2(k_1,i_2,k_2)\\dots \\mathbf{U}_d(k_{d-1},i_d,1)$$"],"metadata":{"id":"uR72uN50PuuM"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"LDCKRGu2Peez"}},{"cell_type":"markdown","source":["Tenemos un tensor $\\mathcal{X}\\in\\mathbb{R}^{n_1\\times\\dots\\times n_d}$ en formato Tensor Train, que tiene $d$ núcleos $U_1,\\dots,U_d$, donde cada núcleo $U_k$ corresponde a una dimensión $k$.\n","\n","El núcleo $U_k$ para $k=1,\\dots,d$ tiene forma $(r_{k-1},n_k,r_k)$, donde:\n","\n","*   $r_{k-1}$: Rango del TT que conecta con el núcleo anterior (para $k=1,r_0=1$).\n","*   $n_k$: Tamaño de la dimensión $k$ del tensor original.\n","*   $r_k$: Rango del TT que conecta al siguiente núcleo (para $k=d,r_d=1$).\n","\n","\n","Por ejemplo, si $\\mathcal{X}$ tiene:\n","\n","*   Dimensiones $n=[n_1,n_2,n_3]=[4,5,6]$.\n","*   Rangos TT $r=[1,3,3,1]$, entonces los núcleos serían:\n","*   $U_1$: $(1,n_1,r_1)=(1,4,3)$,\n","*   $U_2$: $(r_1,n_2,r_2)=(3,5,3)$,\n","*   $U_3$: $(r_2,n_1,r_3)=(3,6,1)$.\n","\n","\n"],"metadata":{"id":"8x9SviFnMYxk"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"TCilltgdPmSQ"}},{"cell_type":"markdown","source":["# Mode-$\\mu$ matrix multiplication"],"metadata":{"id":"noFBqtJCP_T3"}},{"cell_type":"markdown","source":["La multiplicación modo-$\\mu$ entre el tensor $\\mathcal{X}\\in\\mathbb{R}^{n_1\\times\\dots\\times n_d}$ y una matriz $M\\in\\mathbb{R}^{m\\times n_\\mu}$ se define como:\n","\n","$$ \\mathcal{Z}(i_1,\\dots,i_{\\mu-1},j,i_{\\mu+1},\\dots,i_d)=\\sum_{i_\\mu=1}^{n_\\mu}\\mathcal{X}(i_1,\\dots,i_d)M(j,i_\\mu), \\quad j=1,\\dots, m$$\n","\n","Denotaremos a esta operación con $\\mathcal{Z}=\\mathcal{X}\\times_k M$. El tensor resultante es $\\mathcal{Z}\\in\\mathbb{R}^{n_1\\times\\dots\\times n_{\\mu-1}\\times m \\times n_{\\mu+1}\\times \\dots \\times n_d}$.\n","\n","Esto significa que la matriz $M$ \"actúa\" sobre la dimensión $\\mu$ del tensor, reemplazando su tamaño $n_\\mu$ por $m$ (el número de filas de $M$), mientras las demás dimensiones permanecen iguales."],"metadata":{"id":"IGvwPYYZOS9c"}},{"cell_type":"markdown","source":["Para lo que vamos a usar nosotros esta mode-$\\mu$ matrix multiplication:\n","\n","Nuestro objetivo es multiplicar $\\mathcal{P}\\times_1 F_{n}$, donde $F_n\\in\\mathbb{R}^{(n+1)\\times\\dots\\times(n+1)}$ y $\\mathcal{P}$ es el tensor resultado de la compleción tensorial, que está en formato TT.\n","\n","Tener en cuenta que esto lo hacemos con el objetivo de obtener el tensor $\\mathcal{C}$ de coeficientes de Chebyshev. En nuestro caso específico ($\\mu=1$):\n","\n","*   $\\mathcal{P}\\in\\mathbb{R}^{n_1\\times\\dots\\times n_d}$ es el tensor en formato TT.\n","*   $F_{n_1}\\in\\mathbb{R}^{m\\times n_1}$ es la matriz generada por la función de arriba.\n","*   El resultado $\\mathcal{Z}=\\mathcal{P}\\times_1 F_{n_1}$ será un tensor $\\mathcal{Z}\\in\\mathbb{R}^{m\\times n_2\\times\\dots\\times n_d}$.\n","*   La operación modo-1 se define como:\n","$$\\mathcal{Z}(j,i_2,\\dots,i_d)=\\sum_{i_1=1}^{n_1} \\mathcal{P}(i_1,i_2,\\dots,i_d)F_n(j,i_1), \\quad j=1,\\dots,m $$\n","Esta es la definición cuando $\\mathcal{P}$ es denso, cuidado. Esto transforma la primera dimensión de $\\mathcal{P}$ de tamaño $n_1$ a $m$, como si $F_{n_1}$ multiplicara cada \"fibra\" de modo-1 de $\\mathcal{P}$.\n","\n"],"metadata":{"id":"u1sLJSnrX_V1"}},{"cell_type":"markdown","source":["**Multiplicación modo-1 en formato TT**\n","\n","Cuando multiplicamos $\\mathcal{P}$ por $F_{n_1}$ en el modo-1, el objetivo es obtener $\\mathcal{Z}$ también en formato TT. La clave está en que esta operación solo afecta a la primera dimensión de $\\mathcal{P}$, que está representada por el primer núcleo $\\mathbf{U}_1$ (que es un tensor de orden 3). Por tanto, podemos modificar solo $\\mathbf{U}_1$ y mantener los demás núcleos intactos.\n","\n","Por tanto, en este caso $\\mathbf{U}_1$ tiene forma $(1,n_1,r_1)$, $F_{n_1}$ tiene forma $(m,n_1)$, y el resultado debe ser un nuevo núcleo para $\\mathcal{Z}$, con forma $(1,m,r_1)$, porque la dimensión $n_1$ se convierte en $m$, pero los rangos $r_0=1$ y $r_1$ no cambian.\n","\n","**¿Por qué se hace una multiplicación modo-2 del núcleo $\\mathbf{U}_1$?**\n","\n","$\\mathbf{U}_1$ es un tensor de orden 3, y la multiplicación de modo-2 de $\\mathbf{U}_1$ con $F_{n_1}$ significa aplicar $F_{n_1}$ a la segunda dimensión de $\\mathbf{U}_1$ (es decir, $n_1$)."],"metadata":{"id":"yi8J57xgkhUu"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"tVjzg7kOnjVr"}},{"cell_type":"markdown","source":["Para que todo funcione para el algoritmo, debemos suponer entonces que $\\mathcal{P}\\in\\mathbb{R}^{(n_1+1)\\times(n_2+1)\\times\\dots\\times(n_d+1)}$. Esto asegura que se puedan obtener sin problema los núcleos de la descomposición TT de $\\mathcal{Z}$, al hacer la multiplicación modo-2 de cada núcleo $\\mathbf{U}_\\mu$ de $\\mathcal{P}$ por la matriz $F_{n_\\mu}\\in\\mathbb{R}^{(n_\\mu+1)\\times(n_\\mu+1)}$."],"metadata":{"id":"cIcs2URynj6h"}},{"cell_type":"code","source":["import numpy as np\n","\n","def mode_mu_multiply(X, M, mu):\n","    \"\"\"\n","    Realiza la multiplicación modo-\\mu entre un tensor X y una matriz M.\n","\n","    Args:\n","        X (numpy.ndarray): Tensor de entrada de dimensiones (n_1, ..., n_d).\n","        M (numpy.ndarray): Matriz de tamaño (m, n_mu), donde n_mu es el tamaño de la dimensión mu.\n","        mu (int): Índice de la dimensión para la multiplicación (1-based, se ajusta a 0-based internamente).\n","\n","    Returns:\n","        numpy.ndarray: Tensor resultante Z de dimensiones (n_1, ..., n_{mu-1}, m, n_{mu+1}, ..., n_d).\n","\n","    Raises:\n","        ValueError: Si mu está fuera de rango o las dimensiones de M no coinciden con n_mu.\n","    \"\"\"\n","    # Obtener las dimensiones del tensor X\n","    dims = X.shape  # (n_1, n_2, ..., n_d)\n","    d = len(dims)  # Número de dimensiones\n","\n","    # Ajustar mu a 0-based (la ecuación usa 1-based, Python usa 0-based)\n","    if mu < 1 or mu > d:\n","        raise ValueError(f\"El valor de mu debe estar entre 1 y {d}\")\n","    mu = mu - 1  # Convertir a índice basado en 0\n","\n","    # Verificar que la segunda dimensión de M coincida con n_mu\n","    n_mu = dims[mu]\n","    m, n_mu_M = M.shape\n","    if n_mu_M != n_mu:\n","        raise ValueError(f\"La segunda dimensión de M ({n_mu_M}) debe coincidir con n_{mu+1} ({n_mu})\")\n","\n","    # Crear las nuevas dimensiones para el tensor Z\n","    new_dims = list(dims)\n","    new_dims[mu] = m  # Reemplazar n_mu por m en la dimensión mu\n","\n","    # Reorganizar el tensor X para alinear la dimensión mu como última dimensión\n","    # Esto facilita la multiplicación matricial\n","    axes_order = list(range(d))\n","    axes_order.pop(mu)\n","    axes_order.append(mu)  # Mover mu al final: [0, 1, ..., mu-1, mu+1, ..., d-1, mu]\n","    X_permuted = np.transpose(X, axes_order)\n","\n","    # Reformar X_permuted para que sea una matriz donde la última dimensión es n_mu\n","    X_mat = X_permuted.reshape(-1, n_mu)\n","\n","    # Realizar la multiplicación matricial: Z_mat será de tamaño (prod(n_i except n_mu) x m)\n","    Z_mat = np.dot(X_mat, M.T)  # M.T porque queremos M(j, i_mu), no M(i_mu, j)\n","\n","    # Reformar Z_mat de vuelta a las dimensiones del tensor Z\n","    Z_permuted = Z_mat.reshape(*new_dims[0:mu], m, *new_dims[mu+1:])\n","\n","    # Restaurar el orden original de los ejes\n","    inverse_axes = list(range(mu)) + [d-1] + list(range(mu, d-1))\n","    Z = np.transpose(Z_permuted, axes=inverse_axes)\n","\n","    return Z"],"metadata":{"id":"28_FIqDuQNTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ejemplo de uso\n","if __name__ == \"__main__\":\n","    # Crear un tensor X de ejemplo con 3 dimensiones\n","    n1, n2, n3 = 4, 5, 3  # Dimensiones: (n_1, n_2, n_3)\n","    X = np.random.rand(n1, n2, n3)  # Tensor aleatorio de tamaño (4, 5, 3)\n","\n","    # Crear una matriz M para multiplicar en el modo mu=2\n","    m = 3  # Nueva dimensión para reemplazar n_2\n","    M = np.random.rand(m, n2)  # Matriz de tamaño (m, n_2) = (3, 5)\n","    mu = 2  # Multiplicación en la segunda dimensión (1-based)\n","\n","    # Realizar la multiplicación modo-\\mu\n","    Z = mode_mu_multiply(X, M, mu)\n","\n","    # Mostrar resultados\n","    print(\"Dimensiones de X:\", X.shape)  # Debería ser (4, 5, 3)\n","    print(\"Dimensiones de M:\", M.shape)  # Debería ser (3, 5)\n","    print(\"Dimensiones de Z:\", Z.shape)  # Debería ser (4, 3, 3)\n","    print(\"Primeros elementos de Z:\\n\", Z[:2, :2, :2])  # Mostrar una subsección de Z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlx_2_icQPyW","executionInfo":{"status":"ok","timestamp":1741081612840,"user_tz":-60,"elapsed":14,"user":{"displayName":"CLEMENTE ESQUINAS COVES","userId":"18187455758607316569"}},"outputId":"2b054d53-8d34-494a-9639-737d7da1f354"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiones de X: (4, 5, 3)\n","Dimensiones de M: (3, 5)\n","Dimensiones de Z: (4, 3, 3)\n","Primeros elementos de Z:\n"," [[[1.1632701  1.17393088]\n","  [2.25033708 0.9976525 ]]\n","\n"," [[1.56290203 0.97229233]\n","  [2.19525655 1.6140638 ]]]\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"htP_M9l9QGPn"}},{"cell_type":"markdown","source":["Si $\\mathcal{X}$ está en descomposición TT, entonces es fácil obtener una descomposición TT de $\\mathcal{Z}$, haciendo una multiplicación matricial modo-2 de $\\mathbf{U}_\\mu$ con $M$."],"metadata":{"id":"bdiv9c05QG1W"}},{"cell_type":"code","source":["import numpy as np\n","from ttml.tensor_train import TensorTrain\n","\n","def mode_mu_tt_multiply(P, F_n_mu, mu):\n","    \"\"\"\n","    Realiza la multiplicación modo-\\mu entre un tensor TT P y una matriz F_n_mu,\n","    usando mode_mu_multiply para los núcleos y devolviendo Z en formato TT.\n","\n","    Args:\n","        P (TensorTrain): Tensor en formato TT con dimensiones [(n_1+1), ..., (n_d+1)].\n","        F_n_mu (numpy.ndarray): Matriz de tamaño (n_mu + 1, n_mu + 1).\n","        mu (int): Índice de la dimensión para la multiplicación (1-based).\n","\n","    Returns:\n","        TensorTrain: Tensor TT resultante Z = P ×_mu F_n_mu.\n","    \"\"\"\n","    # Ajustar mu a 0-based\n","    if mu < 1 or mu > len(P.dims):\n","        raise ValueError(f\"mu debe estar entre 1 y {len(P.dims)}\")\n","    mu = mu - 1\n","\n","    # Obtener dimensiones y rangos de P\n","    n_mu_plus_1 = P.dims[mu]  # Tamaño de la dimensión mu (n_mu + 1)\n","    m, n_mu_F = F_n_mu.shape\n","    if n_mu_F != n_mu_plus_1 or m != n_mu_plus_1:\n","        raise ValueError(f\"Dimensiones de F_n_mu ({m}x{n_mu_F}) no coinciden con n_mu+1 ({n_mu_plus_1})\")\n","\n","    # Extraer el núcleo U_mu de P, forma (r_{mu-1}, n_mu + 1, r_mu)\n","    core_mu = P.cores[mu]\n","    r_prev, n, r_next = core_mu.shape\n","\n","    # Reorganizar el núcleo para multiplicación modo-2\n","    # Reshape a (r_prev, n_mu + 1, r_next) -> (r_prev * (n_mu + 1), r_next) para modo-1 en denso\n","    reshaped_core = core_mu.reshape(r_prev * n, r_next)\n","\n","    # Usar mode_mu_multiply para realizar la multiplicación modo-1 en formato denso\n","    # Crear un tensor temporal 2D con dimensiones (r_prev * (n_mu + 1), r_next)\n","    temp_tensor_2d = reshaped_core  # (r_prev * (n_mu + 1), r_next)\n","\n","    # Multiplicar modo-1 (ajustamos mu=1 para este núcleo temporal)\n","    Z_temp = mode_mu_multiply(temp_tensor_2d, F_n_mu, 1)  # Modo-1 en el tensor temporal\n","\n","    # Reorganizar el resultado para formar el nuevo núcleo\n","    # Z_temp tiene dimensiones (m, r_next) tras modo-1\n","    new_core_mu = Z_temp.reshape(r_prev, m, r_next)  # (r_prev, n_mu + 1, r_next)\n","\n","    # Crear lista de nuevos cores, reemplazando el núcleo mu\n","    new_cores = [core.copy() for core in P.cores]\n","    new_cores[mu] = new_core_mu\n","\n","    # Crear y devolver el nuevo TensorTrain con los cores modificados\n","    return TensorTrain(new_cores)"],"metadata":{"id":"CmuAM1CpuJje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ejemplo de uso\n","if __name__ == \"__main__\":\n","    # Configurar un tensor TT de ejemplo\n","    n = 4  # Tamaño base para cada dimensión\n","    d = 3  # 3 dimensiones\n","    dims = [n + 1] * d  # Dimensiones: [5, 5, 5]\n","    initial_rank = 3  # Rango inicial consistente\n","\n","    # Crear núcleos iniciales para P\n","    cores = []\n","    for k in range(d):\n","        if k == 0:\n","            cores.append(np.random.rand(1, dims[k], initial_rank))  # (1, 5, 3)\n","        elif k == d - 1:\n","            cores.append(np.random.rand(initial_rank, dims[k], 1))  # (3, 5, 1)\n","        else:\n","            cores.append(np.random.rand(initial_rank, dims[k], initial_rank))  # (3, 5, 3)\n","\n","    P = TensorTrain(cores)\n","\n","    # Generar matriz F_n_mu para mu=1 (n_mu = n = 4)\n","    mu = 1  # Modo-1\n","    F_n_mu = generate_Fn(n)  # Matriz (n + 1) x (n + 1) = (5, 5)\n","\n","    # Realizar la multiplicación modo-1\n","    Z = mode_mu_tt_multiply(P, F_n_mu, mu)\n","\n","    # Mostrar resultados\n","    print(\"Dimensiones originales de P:\", P.dims)  # [5, 5, 5]\n","    print(\"Dimensiones de Z:\", Z.dims)  # [5, 5, 5] (mismo tamaño, ya que F_n_mu es cuadrada)\n","    print(\"Rangos originales de P:\", P.tt_rank)  # [1, 3, 3, 1]\n","    print(\"Rangos de Z:\", Z.tt_rank)  # Debería ser [1, 3, 3, 1] o ajustado"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOgs0Axhujo0","executionInfo":{"status":"ok","timestamp":1741081630933,"user_tz":-60,"elapsed":41,"user":{"displayName":"CLEMENTE ESQUINAS COVES","userId":"18187455758607316569"}},"outputId":"ee711b2b-0141-49ff-c356-0e3c239c824f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiones originales de P: (5, 5, 5)\n","Dimensiones de Z: (5, 5, 5)\n","Rangos originales de P: (3, 3)\n","Rangos de Z: (3, 3)\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"13WnoF76uGvH"}},{"cell_type":"markdown","source":["# Algoritmo 3. Cálculo efficiente de $\\mathcal{C}$ (tensor TT de coeficientes de interpolación de Chebyshev)"],"metadata":{"id":"DeDaTSU4LXca"}},{"cell_type":"markdown","source":["**ESTO ESTÁ EN EL OTRO NOTEBOOK!**"],"metadata":{"id":"aTQLy3wuCQ5E"}},{"cell_type":"markdown","source":["**Entrada:** Tensor $\\mathcal{P}$ en formato TT que contiene los precios en la malla de Chebyshev.\n","\n","**Salida:** Tensor (formato TT) $\\mathcal{C}\\in\\mathbb{R}^{(n_1+1)\\times(n_2+1)\\times\\dots\\times(n_d+1)}$, definido por\n","\n","$$\\mathcal{C}(i_1,i_2,\\dots, i_d)=c_{i_1-1,i_2-1,\\dots,i_d-1} $$\n","\n","para $i_j=1,\\dots,n_j+1$ y $j=1,\\dots, d$.\n","\n","\n","\n","1.   Calcular $F_{n_1}$ con la función `generate_Fn`.\n","2.   $\\mathcal{C}\\leftarrow \\mathcal{P}\\times_1 F_{n_1}$\n","3.   for $m=2,\\dots,d$ do{\n","4.          Calcular $F_{n_m}$\n","5.          $\\mathcal{C}\\leftarrow \\mathcal{C}\\times_m F_{n_m}$}\n","6.   end for\n","\n","**Importante:** Si $n_1=\\dots=n_d$ (caso usual), entonces el algoritmo se simplifica, ya que solo hay que calcular $F_n$ una vez. La estructura particular de las matrices $F_{n_i}$ permite aplicar un algoritmo basado en Fast-Fourier-Transform, que calcula cada multiplicación modo-$\\mu$ en menos tiempo.\n","\n"],"metadata":{"id":"Kf7eW3Cuojvo"}},{"cell_type":"code","source":["import numpy as np\n","from ttml.tensor_train import TensorTrain\n","\n","# Suponiendo que tienes la función mode_mu_multiply como proporcionada\n","def mode_mu_multiply(X, M, mu):\n","    \"\"\"\n","    Realiza la multiplicación modo-\\mu entre un tensor denso X y una matriz M.\n","\n","    Args:\n","        X (numpy.ndarray): Tensor de entrada de dimensiones (n_1, ..., n_d).\n","        M (numpy.ndarray): Matriz de tamaño (m, n_mu).\n","        mu (int): Índice de la dimensión (1-based, se ajusta a 0-based).\n","\n","    Returns:\n","        numpy.ndarray: Tensor resultante Z.\n","    \"\"\"\n","    dims = X.shape\n","    d = len(dims)\n","    if mu < 1 or mu > d:\n","        raise ValueError(f\"El valor de mu debe estar entre 1 y {d}\")\n","    mu = mu - 1\n","\n","    n_mu = dims[mu]\n","    m, n_mu_M = M.shape\n","    if n_mu_M != n_mu:\n","        raise ValueError(f\"La segunda dimensión de M ({n_mu_M}) debe coincidir con n_{mu+1} ({n_mu})\")\n","\n","    new_dims = list(dims)\n","    new_dims[mu] = m\n","\n","    axes_order = list(range(d))\n","    axes_order.pop(mu)\n","    axes_order.append(mu)\n","    X_permuted = np.transpose(X, axes_order)\n","\n","    X_mat = X_permuted.reshape(-1, n_mu)\n","    Z_mat = np.dot(X_mat, M.T)\n","\n","    Z_permuted = Z_mat.reshape(*new_dims[0:mu], m, *new_dims[mu+1:])\n","    inverse_axes = list(range(mu)) + [d-1] + list(range(mu, d-1))\n","    Z = np.transpose(Z_permuted, axes=inverse_axes)\n","\n","    return Z\n","\n","def mode_mu_tt_multiply(P, F_n_mu, mu):\n","    \"\"\"\n","    Realiza la multiplicación modo-\\mu entre un tensor TT P y una matriz F_n_mu,\n","    usando mode_mu_multiply para los núcleos y devolviendo Z en formato TT.\n","\n","    Args:\n","        P (TensorTrain): Tensor en formato TT con dimensiones [(n_1+1), ..., (n_d+1)].\n","        F_n_mu (numpy.ndarray): Matriz de tamaño (n_mu + 1, n_mu + 1).\n","        mu (int): Índice de la dimensión para la multiplicación (1-based).\n","\n","    Returns:\n","        TensorTrain: Tensor TT resultante Z = P ×_mu F_n_mu.\n","    \"\"\"\n","    if mu < 1 or mu > len(P.dims):\n","        raise ValueError(f\"mu debe estar entre 1 y {len(P.dims)}\")\n","    mu = mu - 1\n","\n","    # Obtener dimensiones y rangos de P\n","    n_mu_plus_1 = P.dims[mu]  # Tamaño de la dimensión mu (n_mu + 1)\n","    m, n_mu_F = F_n_mu.shape\n","    if n_mu_F != n_mu_plus_1 or m != n_mu_plus_1:\n","        raise ValueError(f\"Dimensiones de F_n_mu ({m}x{n_mu_F}) no coinciden con n_mu+1 ({n_mu_plus_1})\")\n","\n","    # Extraer el núcleo U_mu de P, forma (r_{mu-1}, n_mu + 1, r_mu)\n","    core_mu = P.cores[mu]\n","    r_prev, n, r_next = core_mu.shape\n","\n","    # Reorganizar el núcleo para multiplicación modo-2\n","    # Reshape a (r_prev, n_mu + 1, r_next) -> (n_mu + 1, r_prev * r_next) para modo-1 en denso\n","    reshaped_core = core_mu.reshape(n, r_prev * r_next)\n","\n","    # Usar mode_mu_multiply para realizar la multiplicación modo-1 en formato denso\n","    # Crear un tensor temporal 2D con dimensiones (n_mu + 1, r_prev * r_next)\n","    temp_tensor_2d = reshaped_core  # (n_mu + 1, r_prev * r_next)\n","\n","    # Multiplicar modo-1 (ajustamos mu=1 para este núcleo temporal)\n","    Z_temp = mode_mu_multiply(temp_tensor_2d, F_n_mu, 1)  # Modo-1 en el tensor temporal\n","\n","    # Reorganizar el resultado para formar el nuevo núcleo\n","    # Z_temp tiene dimensiones (m, r_prev * r_next) tras modo-1\n","    new_core_mu = Z_temp.reshape(r_prev, m, r_next)  # (r_prev, n_mu + 1, r_next)\n","\n","    # Crear lista de nuevos cores, reemplazando el núcleo mu\n","    new_cores = [core.copy() for core in P.cores]\n","    new_cores[mu] = new_core_mu\n","\n","    # Crear y devolver el nuevo TensorTrain con los cores modificados\n","    return TensorTrain(new_cores)\n","\n","def generate_Fn(n):\n","    \"\"\"\n","    Genera la matriz Fn de tamaño (n+1) x (n+1) según la ecuación (11).\n","\n","    Args:\n","        n (int): El parámetro ni, que determina el tamaño de la matriz (n+1) x (n+1).\n","\n","    Returns:\n","        numpy.ndarray: La matriz Fn de tamaño (n+1) x (n+1).\n","    \"\"\"\n","    size = n + 1\n","    F = np.zeros((size, size))\n","    for i in range(size):\n","        for j in range(size):\n","            if (i == 0 and j == 0) or (i == n and j == n):\n","                F[i, j] = 1/4\n","            elif i == 0 or i == n or j == 0 or j == n:\n","                F[i, j] = 1/2 * np.cos(np.pi * i * j / n)\n","            else:\n","                F[i, j] = 1/2 * np.cos(np.pi * (i - 1) * (j - 1) / n)\n","    F = (2 / n) * F\n","    return F\n","\n","def compute_C_efficient(P, n, d):\n","    \"\"\"\n","    Implementa el Algorithm 3 para calcular eficientemente el tensor C en formato TT,\n","    aplicando multiplicaciones modo-\\mu con matrices F_n.\n","\n","    Args:\n","        P (TensorTrain): Tensor TT inicial con dimensiones [(n+1), ..., (n+1)].\n","        n (int): Tamaño base para cada dimensión (n_i = n).\n","        d (int): Número de dimensiones.\n","\n","    Returns:\n","        TensorTrain: Tensor TT C con coeficientes de Chebyshev.\n","    \"\"\"\n","    # Paso 1: Computar F_n1 como en (11)\n","    F_n1 = generate_Fn(n)\n","\n","    # Paso 2: C ← P ×_1 F_n1\n","    C = mode_mu_tt_multiply(P, F_n1, 1)  # Multiplicación modo-1\n","\n","    # Paso 3: Iterar sobre m = 2, ..., d\n","    for m in range(2, d + 1):\n","        # Paso 4: Computar F_nm\n","        F_nm = generate_Fn(n)\n","\n","        # Paso 5: C ← C ×_m F_nm\n","        C = mode_mu_tt_multiply(C, F_nm, m)  # Multiplicación modo-m\n","\n","    # Paso 6: Devolver C\n","    return C\n","\n","# Ejemplo de uso\n","if __name__ == \"__main__\":\n","    # Configurar un tensor TT de ejemplo\n","    n = 4  # Tamaño base para cada dimensión\n","    d = 3  # 3 dimensiones\n","    dims = [n + 1] * d  # Dimensiones: [5, 5, 5]\n","    initial_rank = 3  # Rango inicial consistente\n","\n","    # Crear núcleos iniciales para P\n","    cores = []\n","    for k in range(d):\n","        if k == 0:\n","            cores.append(np.random.rand(1, dims[k], initial_rank))  # (1, 5, 3)\n","        elif k == d - 1:\n","            cores.append(np.random.rand(initial_rank, dims[k], 1))  # (3, 5, 1)\n","        else:\n","            cores.append(np.random.rand(initial_rank, dims[k], initial_rank))  # (3, 5, 3)\n","\n","    P = TensorTrain(cores)\n","\n","    # Computar C usando el algoritmo eficiente\n","    C = compute_C_efficient(P, n, d)\n","\n","    # Mostrar resultados\n","    print(\"Dimensiones de P:\", P.dims)  # [5, 5, 5]\n","    print(\"Dimensiones de C:\", C.dims)  # [5, 5, 5]\n","    print(\"Rangos de P:\", P.tt_rank)  # [1, 3, 3, 1]\n","    print(\"Rangos de C:\", C.tt_rank)  # Debería ser [1, 3, 3, 1] o ajustado"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-9YOULasbnA","executionInfo":{"status":"ok","timestamp":1741081630956,"user_tz":-60,"elapsed":22,"user":{"displayName":"CLEMENTE ESQUINAS COVES","userId":"18187455758607316569"}},"outputId":"1851f1d5-d621-40bf-d57b-656faa756ba7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiones de P: (5, 5, 5)\n","Dimensiones de C: (5, 5, 5)\n","Rangos de P: (3, 3)\n","Rangos de C: (3, 3)\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"aj4-T9KYCUZI"}}]}