{"cells":[{"cell_type":"markdown","id":"4a193ed2","metadata":{"id":"4a193ed2"},"source":["# Riemannian Tensor Completion with T3F\n","\n","This notebook replicates the results of the paper *Low-rank tensor approximation for Chebyshev interpolation in parametric option pricing* by Kathrin Glau, Daniel Kressner, and Francesco Statti. The goal is to generalize the Riemannian tensor completion algorithm to interpolate tensorized functions of higher dimensionality (around 10) and complexity, with applications to high-dimensional Credit Valuation Adjustment (CVA) modeling.\n","\n","The core techniques involve the Tensor Train (TT) format, Riemannian Conjugate Gradient optimization, and Chebyshev interpolation."]},{"cell_type":"markdown","id":"bbcdbb8d","metadata":{"id":"bbcdbb8d"},"source":["# Installation"]},{"cell_type":"markdown","id":"ddc79650","metadata":{"id":"ddc79650"},"source":["To properly install the `t3f` package, you must run the following two cells and then restart the session so that the updated files take effect."]},{"cell_type":"code","execution_count":null,"id":"3e31975b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3e31975b","outputId":"fb66170e-a2b4-46dd-811e-e6ae44870e4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting t3f\n","  Downloading t3f-1.2.0.tar.gz (57 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from t3f) (2.0.2)\n","Building wheels for collected packages: t3f\n","  Building wheel for t3f (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for t3f: filename=t3f-1.2.0-py3-none-any.whl size=69159 sha256=6b39e92c76a619625008eaf6921166aa05378abc7898824ac5e7ce9b52bfc5e8\n","  Stored in directory: /root/.cache/pip/wheels/36/ce/e5/723e43d13ef4de2e16b41e4f1aca48d999fc1528b3538277f5\n","Successfully built t3f\n","Installing collected packages: t3f\n","Successfully installed t3f-1.2.0\n","El archivo /usr/local/lib/python3.11/dist-packages/t3f/initializers.py ha sido modificado exitosamente!\n"]}],"source":["!pip install t3f\n","\n","import os\n","\n","# Ruta al archivo initializers.py\n","init_file_path = '/usr/local/lib/python3.11/dist-packages/t3f/initializers.py'\n","\n","# Nueva versión de random_tensor con docstring correctamente formateado\n","new_random_tensor = '''def random_tensor(shape, tt_rank=2, mean=0., stddev=1., dtype=tf.float32,\n","                  name='t3f_random_tensor'):\n","    \"\"\"Generate a random TT-tensor of the given shape with given mean and stddev.\n","\n","    Entries of the generated tensor (in the full format) will be iid and satisfy\n","    E[x_{i1i2..id}] = mean, Var[x_{i1i2..id}] = stddev^2, but the distribution is\n","    in fact not Gaussian (but is close for large tensors).\n","\n","    In the current implementation only mean 0 is supported. To get\n","    a random_tensor with specified mean but tt_rank greater by 1 you can\n","    call:\n","        x = t3f.random_tensor(shape, tt_rank, stddev=stddev)\n","        x = mean * t3f.ones_like(x) + x\n","\n","    Args:\n","        shape: array representing the shape of the future tensor.\n","        tt_rank: a number or a (d+1)-element array with the desired ranks.\n","        mean: a number, the desired mean for the distribution of entries.\n","        stddev: a number, the desired standard deviation for the distribution of\n","            entries.\n","        dtype: [tf.float32] dtype of the resulting tensor.\n","        name: string, name of the Op.\n","\n","    Returns:\n","        TensorTrain containing a TT-tensor\n","    \"\"\"\n","    shape = np.array(shape)\n","    tt_rank = np.array(tt_rank)\n","    _validate_input_parameters(is_tensor=True, shape=shape, tt_rank=tt_rank)\n","\n","    num_dims = shape.size\n","    if tt_rank.size == 1:\n","        tt_rank = tt_rank * np.ones(num_dims - 1, dtype=int)\n","        tt_rank = np.insert(tt_rank, 0, 1)\n","        tt_rank = np.append(tt_rank, 1)\n","\n","    tt_rank = tt_rank.astype(int)\n","\n","    # Empirically entries of a TT tensor with cores initialized from N(0, 1)\n","    # will have variances np.prod(tt_rank) and mean 0.\n","    # We scale each TT-core to obtain the desired stddev\n","    cr_exponent = -1.0 / (2 * num_dims)\n","    var = np.prod(tt_rank ** cr_exponent)\n","    core_stddev = stddev ** (1.0 / num_dims) * var\n","    with tf.name_scope(name):\n","        tt = tensor_with_random_cores(shape, tt_rank=tt_rank, stddev=core_stddev,\n","                                      dtype=dtype)\n","\n","    if np.abs(mean) < 1e-8:\n","        return tt\n","    else:\n","        raise NotImplementedError('non-zero mean is not supported yet')\n","'''\n","\n","# Verificar si el archivo existe y modificarlo\n","if os.path.exists(init_file_path):\n","    # Leer el contenido actual\n","    with open(init_file_path, 'r') as f:\n","        content = f.read()\n","\n","    # 1. Añadir el nuevo import después de \"from t3f import shapes\"\n","    import_line = 'from t3f import shapes'\n","    new_import = 'from numbers import Integral as integer'\n","    if new_import not in content:\n","        # Asegurarse de que el import se añada solo una vez y en la posición correcta\n","        content = content.replace(import_line, f\"{import_line}\\n{new_import}\", 1)\n","\n","    # 2. Reemplazar la función random_tensor de manera más robusta\n","    start_marker = 'def random_tensor('\n","    try:\n","        start_idx = content.index(start_marker)\n","        # Buscar el final de la función buscando la siguiente definición o el final del archivo\n","        next_func_marker = 'def '\n","        end_idx = content.find(next_func_marker, start_idx + len(start_marker))\n","        if end_idx == -1:  # Si no hay más funciones, ir al final del archivo\n","            end_idx = len(content)\n","        else:\n","            # Retroceder hasta encontrar el final real de la función (antes de la próxima definición)\n","            end_idx = content.rfind('\\n\\n', start_idx, end_idx)\n","            if end_idx == -1:\n","                end_idx = content.rfind('\\n', start_idx, end_idx)\n","\n","        # Construir el nuevo contenido\n","        new_content = content[:start_idx] + new_random_tensor + content[end_idx:]\n","\n","        # Escribir el contenido modificado\n","        with open(init_file_path, 'w') as f:\n","            f.write(new_content)\n","\n","        print(f\"El archivo {init_file_path} ha sido modificado exitosamente!\")\n","    except ValueError as e:\n","        print(f\"Error al encontrar marcadores en el archivo: {e}\")\n","else:\n","    print(f\"El archivo {init_file_path} no existe o no es accesible.\")"]},{"cell_type":"markdown","id":"a285e1cf","metadata":{"id":"a285e1cf"},"source":["This cell is used to check that the files have been correctly modified.\n","\n","If you see the following line in the import section at the beginning of the file, it means everything is set up properly:\n","\n","```\n","from numbers import Integral as integer\n","```"]},{"cell_type":"code","execution_count":null,"id":"0f3d0a77","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0f3d0a77","outputId":"5121aa49-dd44-4b8f-8b03-023dca660db8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Contenido del archivo /usr/local/lib/python3.11/dist-packages/t3f/initializers.py:\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","from t3f.tensor_train import TensorTrain\n","from t3f.tensor_train_batch import TensorTrainBatch\n","from t3f.tensor_train_base import TensorTrainBase\n","from t3f import shapes\n","from numbers import Integral as integer\n","\n","\n","def _validate_input_parameters(is_tensor, shape, **params):\n","  \"\"\"Internal function for validating input parameters\n","\n","  Args:\n","    is_tensor: bool, determines whether we attempt to construct a TT-tensor or\n","      a TT-matrix (needed for the correct shape checks).\n","    shape: array, the desired shape of the generated TT object\n","    params: optional, possible values:\n","      batch_size: int, for constructing batches\n","      tt_rank: array or int, desired TT-ranks\n","  \"\"\"\n","\n","  if is_tensor:\n","    if len(shape.shape) != 1:\n","      raise ValueError('shape should be 1d array, got %a' % shape)\n","    if np.any(shape < 1):\n","      raise ValueError('all elements in `shape` should be positive, got %a' %\n","                       shape)\n","    if not all(isinstance(sh, np.integer) for sh in shape):\n","      raise ValueError('all elements in `shape` should be integers, got %a' %\n","                       shape)\n","  else:\n","    if len(shape.shape) != 2:\n","      raise ValueError('shape should be 2d array, got %a' % shape)\n","    if shape[0].size != shape[1].size:\n","      raise ValueError('shape[0] should have the same length as shape[1], but'\n","                       'got %d and %d' % (shape[0].size, shape[1].size))\n","    if np.any(shape.flatten() < 1):\n","      raise ValueError('all elements in `shape` should be positive, got %a' %\n","                       shape)\n","    if not all(isinstance(sh, np.integer) for sh in shape.flatten()):\n","      raise ValueError('all elements in `shape` should be integers, got %a' %\n","                       shape)\n","\n","  if 'batch_size' in params:\n","    batch_size = params['batch_size']\n","    if not isinstance(batch_size, (int, np.integer)):\n","      raise ValueError('`batch_size` should be integer, got %f' % batch_size)\n","    if batch_size < 1:\n","      raise ValueError('Batch size should be positive, got %d' % batch_size)\n","  if 'tt_rank' in params:\n","    tt_rank = params['tt_rank']\n","    if tt_rank.size == 1:\n","      if not isinstance(tt_rank[()], np.integer):\n","        raise ValueError('`tt_rank` should be integer, got %f' % tt_rank[()])\n","    if tt_rank.size > 1:\n","      if not all(isinstance(tt_r, np.integer) for tt_r in tt_rank):\n","        raise ValueError('all elements in `tt_rank` should be integers, got'\n","                         ' %a' % tt_rank)\n","    if np.any(tt_rank < 1):\n","      raise ValueError('`tt_rank` should be positive, got %a' % tt_rank)\n","\n","    if is_tensor:\n","      if tt_rank.size != 1 and tt_rank.size != (shape.size + 1):\n","        raise ValueError('`tt_rank` array has inappropriate size, expected'\n","                         '1 or %d, got %d' % (shape.size + 1, tt_rank.size))\n","    else:\n","      if tt_rank.size != 1 and tt_rank.size != (shape[0].size + 1):\n","        raise ValueError('`tt_rank` array has inappropriate size, expected'\n","                         '1 or %d, got %d' % (shape[0].size + 1, tt_rank.size))\n","\n","\n","def tensor_ones(shape, dtype=tf.float32, name='t3f_tensor_ones'):\n","  \"\"\"Generate TT-tensor of the given shape with all entries equal to 1.\n","\n","  Args:\n","    shape: array representing the shape of the future tensor\n","    dtype: [tf.float32] dtype of the resulting tensor.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain object containing a TT-tensor\n","  \"\"\"\n","\n","  shape = np.array(shape)\n","  _validate_input_parameters(is_tensor=True, shape=shape)\n","  num_dims = shape.size\n","  tt_rank = np.ones(num_dims + 1, dtype=np.int)\n","\n","  with tf.name_scope(name):\n","    tt_cores = num_dims * [None]\n","    for i in range(num_dims):\n","      curr_core_shape = (1, shape[i], 1)\n","      tt_cores[i] = tf.ones(curr_core_shape, dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def tensor_zeros(shape, dtype=tf.float32, name='t3f_tensor_zeros'):\n","  \"\"\"Generate TT-tensor of the given shape with all entries equal to 0.\n","\n","  Args:\n","    shape: array representing the shape of the future tensor\n","    dtype: [tf.float32] dtype of the resulting tensor.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain object containing a TT-tensor\n","  \"\"\"\n","\n","  shape = np.array(shape)\n","  _validate_input_parameters(is_tensor=True, shape=shape)\n","  num_dims = shape.size\n","  tt_rank = np.ones(num_dims + 1, dtype=np.int)\n","  tt_cores = num_dims * [None]\n","  with tf.name_scope(name):\n","    for i in range(num_dims):\n","      curr_core_shape = (1, shape[i], 1)\n","      tt_cores[i] = tf.zeros(curr_core_shape, dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def eye(shape, dtype=tf.float32, name='t3f_eye'):\n","  \"\"\"Creates an identity TT-matrix.\n","\n","  Args:\n","    shape: array which defines the shape of the matrix row and column\n","      indices.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing an identity TT-matrix of size\n","    np.prod(shape) x np.prod(shape)\n","  \"\"\"\n","  shape = np.array(shape)\n","  # In this special case shape is in the same format as in the TT-tensor case\n","  _validate_input_parameters(is_tensor=True, shape=shape)\n","\n","  num_dims = shape.size\n","  tt_ranks = np.ones(num_dims + 1, dtype=np.int)\n","\n","  with tf.name_scope(name):\n","    tt_cores = num_dims * [None]\n","    for i in range(num_dims):\n","      curr_core_shape = (1, shape[i], shape[i], 1)\n","      tt_cores[i] = tf.reshape(tf.eye(shape[i], dtype=dtype), curr_core_shape)\n","\n","    true_shape = np.vstack([shape, shape])\n","    return TensorTrain(tt_cores, true_shape, tt_ranks)\n","\n","\n","def matrix_ones(shape, dtype=tf.float32, name='t3f_matrix_ones'):\n","  \"\"\"Generate a TT-matrix of the given shape with each entry equal to 1.\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        matrix_ones([[2, 2, 2], None])\n","      and\n","        matrix_ones([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1]) with each entry equal to 1\n","  \"\"\"\n","\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","\n","  _validate_input_parameters(is_tensor=False, shape=shape)\n","\n","  num_dims = shape[0].size\n","  tt_rank = np.ones(shape[0].size + 1, dtype=np.int)\n","\n","  with tf.name_scope(name):\n","    tt_cores = [None] * num_dims\n","    for i in range(num_dims):\n","      curr_core_shape = (1, shape[0][i], shape[1][i], 1)\n","      tt_cores[i] = tf.ones(curr_core_shape, dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def matrix_zeros(shape, dtype=tf.float32, name='t3f_matrix_zeros'):\n","  \"\"\"Generate a TT-matrix of the given shape with each entry equal to 0.\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        matrix_zeros([[2, 2, 2], None])\n","      and\n","        matrix_zeros([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1]) with each entry equal to 0\n","  \"\"\"\n","\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","\n","  _validate_input_parameters(is_tensor=False, shape=shape)\n","  num_dims = shape[0].size\n","  tt_rank = np.ones(shape[0].size + 1, dtype=np.int)\n","\n","  with tf.name_scope(name):\n","    tt_cores = [None] * num_dims\n","    for i in range(num_dims):\n","      curr_core_shape = (1, shape[0][i], shape[1][i], 1)\n","      tt_cores[i] = tf.zeros(curr_core_shape, dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def tensor_with_random_cores(shape, tt_rank=2, mean=0., stddev=1.,\n","                             dtype=tf.float32,\n","                             name='t3f_tensor_with_random_cores'):\n","  \"\"\"Generate a TT-tensor of the given shape with N(mean, stddev^2) cores.\n","\n","  Args:\n","    shape: array representing the shape of the future tensor.\n","    tt_rank: a number or a (d+1)-element array with the desired ranks.\n","    mean: a number, the mean of the normal distribution used for\n","      initializing TT-cores.\n","    stddev: a number, the standard deviation of the normal distribution used\n","      for initializing TT-cores.\n","    dtype: [tf.float32] dtype of the resulting tensor.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-tensor\n","  \"\"\"\n","  # TODO: good distribution to init training.\n","  # TODO: support shape and tt_ranks as TensorShape?.\n","  # TODO: support None as a dimension.\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=True, shape=shape, tt_rank=tt_rank)\n","  num_dims = shape.size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.insert(tt_rank, 0, 1)\n","    tt_rank = np.append(tt_rank, 1)\n","\n","  tt_rank = tt_rank.astype(int)\n","  tt_cores = [None] * num_dims\n","  with tf.name_scope(name):\n","    for i in range(num_dims):\n","      curr_core_shape = (tt_rank[i], shape[i], tt_rank[i + 1])\n","      tt_cores[i] = tf.random.normal(curr_core_shape, mean=mean, stddev=stddev,\n","                                     dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def tensor_batch_with_random_cores(shape, tt_rank=2, batch_size=1,\n","                                   mean=0., stddev=1., dtype=tf.float32,\n","                                   name='t3f_tensor_batch_with_random_cores'):\n","  \"\"\"Generate a batch of TT-tensors of given shape with N(mean, stddev^2) cores.\n","\n","  Args:\n","    shape: array representing the shape of the future tensor.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    batch_size: an integer.\n","    mean: a number, the mean of the normal distribution used for\n","      initializing TT-cores.\n","    stddev: a number, the standard deviation of the normal distribution used\n","      for initializing TT-cores.\n","    dtype: [tf.float32] dtype of the resulting tensor.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrainBatch containing TT-tensors\n","  \"\"\"\n","\n","  # TODO: support shape and tt_ranks as TensorShape?.\n","  # TODO: support None as a dimension.\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=True, shape=shape, tt_rank=tt_rank,\n","                             batch_size=batch_size)\n","  num_dims = shape.size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.insert(tt_rank, 0, 1)\n","    tt_rank = np.append(tt_rank, 1)\n","  tt_rank = tt_rank.astype(int)\n","  tt_cores = [None] * num_dims\n","  with tf.name_scope(name):\n","    for i in range(num_dims):\n","      curr_core_shape = (batch_size, tt_rank[i], shape[i], tt_rank[i + 1])\n","      tt_cores[i] = tf.random.normal(curr_core_shape, mean=mean, stddev=stddev,\n","                                     dtype=dtype)\n","\n","    return TensorTrainBatch(tt_cores, shape, tt_rank, batch_size)\n","\n","\n","def matrix_with_random_cores(shape, tt_rank=2, mean=0., stddev=1.,\n","                             dtype=tf.float32,\n","                             name='t3f_matrix_with_random_cores'):\n","  \"\"\"Generate a TT-matrix of given shape with N(mean, stddev^2) cores.\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        matrix_with_random_cores([[2, 2, 2], None])\n","      and\n","        matrix_with_random_cores([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    mean: a number, the mean of the normal distribution used for\n","      initializing TT-cores.\n","    stddev: a number, the standard deviation of the normal distribution used\n","      for initializing TT-cores.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","  # TODO: good distribution to init training.\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank)\n","\n","  num_dims = shape[0].size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.concatenate([[1], tt_rank, [1]])\n","\n","  tt_rank = tt_rank.astype(int)\n","  tt_cores = [None] * num_dims\n","  with tf.name_scope(name):\n","    for i in range(num_dims):\n","      curr_core_shape = (tt_rank[i], shape[0][i], shape[1][i],\n","                         tt_rank[i + 1])\n","      tt_cores[i] = tf.random.normal(curr_core_shape, mean=mean, stddev=stddev,\n","                                     dtype=dtype)\n","\n","    return TensorTrain(tt_cores, shape, tt_rank)\n","\n","\n","def matrix_batch_with_random_cores(shape, tt_rank=2, batch_size=1,\n","                                   mean=0., stddev=1., dtype=tf.float32,\n","                                   name='t3f_matrix_batch_with_random_cores'):\n","  \"\"\"Generate a batch of TT-matrices of given shape with N(mean, stddev^2) cores.\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        matrix_batch_with_random_cores([[2, 2, 2], None])\n","      and\n","        matrix_batch_with_random_cores([None, [2, 2, 2]])\n","    will create a batch of one 8-element column and row vector correspondingly.\n","\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    batch_size: an integer.\n","    mean: a number, the mean of the normal distribution used for\n","      initializing TT-cores.\n","    stddev: a number, the standard deviation of the normal distribution used\n","      for initializing TT-cores.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrainBatch containing a batch of TT-matrices of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","  # TODO: good distribution to init training.\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank,\n","                             batch_size=batch_size)\n","  num_dims = shape[0].size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.concatenate([[1], tt_rank, [1]])\n","  shape = shape.astype(int)\n","  tt_rank = tt_rank.astype(int)\n","  tt_cores = [None] * num_dims\n","  with tf.name_scope(name):\n","    for i in range(num_dims):\n","      curr_core_shape = (batch_size, tt_rank[i], shape[0][i], shape[1][i],\n","                         tt_rank[i + 1])\n","      tt_cores[i] = tf.random.normal(curr_core_shape, mean=mean, stddev=stddev,\n","                                     dtype=dtype)\n","\n","    return TensorTrainBatch(tt_cores, shape, tt_rank, batch_size)\n","\n","\n","def ones_like(tt, name='t3f_ones_like'):\n","  \"\"\"Constructs t3f.ones with the shape of `tt`.\n","\n","  In the case when `tt` is TensorTrainBatch constructs t3f.ones with the shape\n","  of a TensorTrain in `tt`.\n","\n","  Args:\n","    tt: TensorTrain object\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain object of the same shape as `tt` but with all entries equal to\n","    1.\n","\n","  \"\"\"\n","  if not isinstance(tt, TensorTrainBase):\n","    raise ValueError(\"`tt` has to be a Tensor Train object\")\n","  else:\n","    shape = shapes.lazy_raw_shape(tt)\n","    # I guess variables=tt.tt_cores is not needed here since the output of\n","    # the function doesn't depend on the values of the TT-cores, only on their\n","    # shapes etc. But I'm not 100% sure.\n","    with tf.name_scope(name):\n","      if tt.is_tt_matrix():\n","        return matrix_ones(shape, dtype=tt.dtype)\n","      else:\n","        return tensor_ones(shape[0, :], dtype=tt.dtype)\n","\n","\n","def zeros_like(tt, name='t3f_zeros_like'):\n","  \"\"\"Constructs t3f.zeros with the shape of `tt`.\n","\n","  In the case when `tt` is a TensorTrainBatch constructs t3f.zeros with\n","  the shape of a TensorTrain in `tt`.\n","\n","  Args:\n","    tt: TensorTrain object\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain object of the same shape as `tt` but with all entries equal to\n","    0.\n","\n","  \"\"\"\n","  if not isinstance(tt, TensorTrainBase):\n","    raise ValueError(\"`tt` has to be a Tensor Train object\")\n","  else:\n","    shape = shapes.lazy_raw_shape(tt)\n","    # I guess variables=tt.tt_cores is not needed here since the output of\n","    # the function doesn't depend on the values of the TT-cores, only on their\n","    # shapes etc. But I'm not 100% sure.\n","    with tf.name_scope(name):\n","      if tt.is_tt_matrix():\n","        return matrix_zeros(shape, dtype=tt.dtype)\n","      else:\n","        return tensor_zeros(shape[0, :], dtype=tt.dtype)\n","\n","\n","def random_tensor(shape, tt_rank=2, mean=0., stddev=1., dtype=tf.float32,\n","                  name='t3f_random_tensor'):\n","    \"\"\"Generate a random TT-tensor of the given shape with given mean and stddev.\n","\n","    Entries of the generated tensor (in the full format) will be iid and satisfy\n","    E[x_{i1i2..id}] = mean, Var[x_{i1i2..id}] = stddev^2, but the distribution is\n","    in fact not Gaussian (but is close for large tensors).\n","\n","    In the current implementation only mean 0 is supported. To get\n","    a random_tensor with specified mean but tt_rank greater by 1 you can\n","    call:\n","        x = t3f.random_tensor(shape, tt_rank, stddev=stddev)\n","        x = mean * t3f.ones_like(x) + x\n","\n","    Args:\n","        shape: array representing the shape of the future tensor.\n","        tt_rank: a number or a (d+1)-element array with the desired ranks.\n","        mean: a number, the desired mean for the distribution of entries.\n","        stddev: a number, the desired standard deviation for the distribution of\n","            entries.\n","        dtype: [tf.float32] dtype of the resulting tensor.\n","        name: string, name of the Op.\n","\n","    Returns:\n","        TensorTrain containing a TT-tensor\n","    \"\"\"\n","    shape = np.array(shape)\n","    tt_rank = np.array(tt_rank)\n","    _validate_input_parameters(is_tensor=True, shape=shape, tt_rank=tt_rank)\n","\n","    num_dims = shape.size\n","    if tt_rank.size == 1:\n","        tt_rank = tt_rank * np.ones(num_dims - 1, dtype=int)\n","        tt_rank = np.insert(tt_rank, 0, 1)\n","        tt_rank = np.append(tt_rank, 1)\n","\n","    tt_rank = tt_rank.astype(int)\n","\n","    # Empirically entries of a TT tensor with cores initialized from N(0, 1)\n","    # will have variances np.prod(tt_rank) and mean 0.\n","    # We scale each TT-core to obtain the desired stddev\n","    cr_exponent = -1.0 / (2 * num_dims)\n","    var = np.prod(tt_rank ** cr_exponent)\n","    core_stddev = stddev ** (1.0 / num_dims) * var\n","    with tf.name_scope(name):\n","        tt = tensor_with_random_cores(shape, tt_rank=tt_rank, stddev=core_stddev,\n","                                      dtype=dtype)\n","\n","    if np.abs(mean) < 1e-8:\n","        return tt\n","    else:\n","        raise NotImplementedError('non-zero mean is not supported yet')\n","\n","\n","def random_tensor_batch(shape, tt_rank=2, batch_size=1, mean=0., stddev=1.,\n","                        dtype=tf.float32, name='t3f_random_tensor_batch'):\n","  \"\"\"Generate a batch of TT-tensors with given shape, mean and stddev.\n","\n","  Entries of the generated tensors (in the full format) will be iid and satisfy\n","  E[x_{i1i2..id}] = mean, Var[x_{i1i2..id}] = stddev^2, but the distribution is\n","  in fact not Gaussian (but is close for large tensors).\n","\n","  In the current implementation only mean 0 is supported. To get\n","  a random_tensor_batch with specified mean but tt_rank greater by 1 you can\n","  call\n","  x = t3f.random_tensor_batch(shape, tt_rank, batch_size=bs, stddev=stddev)\n","  x = mean * t3f.ones_like(x) + x\n","\n","  Args:\n","    shape: array representing the shape of the future tensor.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    batch_size: an integer.\n","    mean: a number, the desired mean for the distribution of entries.\n","    stddev: a number, the desired standard deviation for the distribution of\n","      entries.\n","    dtype: [tf.float32] dtype of the resulting tensor.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrainBatch containing TT-tensors.\n","  \"\"\"\n","  # TODO: support shape and tt_ranks as TensorShape?.\n","  # TODO: support None as a dimension.\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=True, shape=shape, tt_rank=tt_rank,\n","                             batch_size=batch_size)\n","  num_dims = shape.size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.insert(tt_rank, 0, 1)\n","    tt_rank = np.append(tt_rank, 1)\n","  tt_rank = tt_rank.astype(int)\n","\n","  cr_exponent = -1.0 / (2 * num_dims)\n","  var = np.prod(tt_rank ** cr_exponent)\n","  cr_stddev = stddev ** (1.0 / num_dims) * var\n","  with tf.name_scope(name):\n","    tt = tensor_batch_with_random_cores(shape, tt_rank=tt_rank, stddev=cr_stddev,\n","                                        batch_size=batch_size, dtype=dtype)\n","\n","  if np.abs(mean) < 1e-8:\n","    return tt\n","  else:\n","    raise NotImplementedError('non-zero mean is not supported yet')\n","\n","\n","def random_matrix(shape, tt_rank=2, mean=0., stddev=1.,\n","                  dtype=tf.float32, name='t3f_random_matrix'):\n","  \"\"\"Generate a random TT-matrix of the given shape with given mean and stddev.\n","\n","  Entries of the generated matrix (in the full format) will be iid and satisfy\n","  E[x_{i1i2..id}] = mean, Var[x_{i1i2..id}] = stddev^2, but the distribution is\n","  in fact not Gaussian.\n","\n","  In the current implementation only mean 0 is supported. To get\n","  a random_matrix with specified mean but tt_rank greater by 1 you can call\n","  x = t3f.random_matrix(shape, tt_rank, stddev=stddev)\n","  x = mean * t3f.ones_like(x) + x\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        random_matrix([[2, 2, 2], None])\n","      and\n","        random_matrix([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    mean: a number, the desired mean for the distribution of entries.\n","    stddev: a number, the desired standard deviation for the distribution of\n","      entries.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","  # TODO: good distribution to init training.\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank)\n","\n","  num_dims = shape[0].size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.concatenate([[1], tt_rank, [1]])\n","\n","  tt_rank = tt_rank.astype(int)\n","  var = np.prod(tt_rank)\n","\n","  # Empirically entries of a TT tensor with cores initialized from N(0, 1)\n","  # will have variances np.prod(tt_rank) and mean 0.\n","  # We scale each TT-core to obtain the desired stddev\n","\n","  cr_exponent = -1.0 / (2 * num_dims)\n","  var = np.prod(tt_rank ** cr_exponent)\n","  core_stddev = stddev ** (1.0 / num_dims) * var\n","  with tf.name_scope(name):\n","    tt = matrix_with_random_cores(shape, tt_rank=tt_rank, stddev=core_stddev,\n","                                  dtype=dtype)\n","\n","  if np.abs(mean) < 1e-8:\n","    return tt\n","  else:\n","    raise NotImplementedError('non-zero mean is not supported yet')\n","\n","\n","def random_matrix_batch(shape, tt_rank=2, batch_size=1, mean=0., stddev=1.,\n","                        dtype=tf.float32, name='t3f_random_matrix_batch'):\n","  \"\"\"Generate a batch of TT-matrices with given shape, mean and stddev.\n","\n","  Entries of the generated matrices (in the full format) will be iid and\n","  satisfy E[x_{i1i2..id}] = mean, Var[x_{i1i2..id}] = stddev^2, but the\n","  distribution is in fact not Gaussian.\n","\n","  In the current implementation only mean 0 is supported. To get a\n","  random_matrix_batch with specified mean but tt_rank greater by 1 you can call\n","  x = t3f.random_matrix_batch(shape, tt_rank, batch_size=bs, stddev=stddev)\n","  x = mean * t3f.ones_like(x) + x\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        random_matrix_batch([[2, 2, 2], None])\n","      and\n","        random_matrix_batch([None, [2, 2, 2]])\n","    will create a batch of one 8-element column and row vector correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    batch_size: an integer.\n","    mean: a number, the desired mean for the distribution of entries.\n","    stddev: a number, the desired standard deviation for the distribution of\n","      entries.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrainBatch containing a batch of TT-matrices of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank,\n","                             batch_size=batch_size)\n","  num_dims = shape[0].size\n","  if tt_rank.size == 1:\n","    tt_rank = tt_rank * np.ones(num_dims - 1, dtype=np.int)\n","    tt_rank = np.concatenate([[1], tt_rank, [1]])\n","\n","  shape = shape.astype(int)\n","  tt_rank = tt_rank.astype(int)\n","\n","  cr_exponent = -1.0 / (2 * num_dims)\n","  var = np.prod(tt_rank ** cr_exponent)\n","  core_stddev = stddev ** (1.0 / num_dims) * var\n","  with tf.name_scope(name):\n","    tt = matrix_batch_with_random_cores(shape, tt_rank=tt_rank,\n","                                        stddev=core_stddev,\n","                                        batch_size=batch_size,\n","                                        dtype=dtype)\n","\n","  if np.abs(mean) < 1e-8:\n","    return tt\n","  else:\n","    raise NotImplementedError('non-zero mean is not supported yet')\n","\n","\n","def glorot_initializer(shape, tt_rank=2, dtype=tf.float32,\n","                       name='t3f_glorot_initializer'):\n","  \"\"\"Constructs a random TT matrix with entrywise variance 2.0 / (n_in + n_out)\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        glorot_initializer([[2, 2, 2], None])\n","      and\n","        glorot_initializer([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank)\n","  n_in = np.prod(shape[0])\n","  n_out = np.prod(shape[1])\n","  lamb = 2.0 / (n_in + n_out)\n","\n","  with tf.name_scope(name):\n","    return random_matrix(shape, tt_rank=tt_rank, stddev=np.sqrt(lamb),\n","                         dtype=dtype)\n","\n","\n","def he_initializer(shape, tt_rank=2, dtype=tf.float32,\n","                   name='t3f_he_initializer'):\n","  \"\"\"Constructs a random TT matrix with entrywise variance 2.0 / n_in\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        he_initializer([[2, 2, 2], None])\n","      and\n","        he_initializer([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank)\n","  n_in = np.prod(shape[0])\n","  lamb = 2.0 / n_in\n","\n","  with tf.name_scope(name):\n","    return random_matrix(shape, tt_rank=tt_rank, stddev=np.sqrt(lamb),\n","                         dtype=dtype)\n","\n","\n","def lecun_initializer(shape, tt_rank=2, dtype=tf.float32,\n","                      name='t3f_lecun_initializer'):\n","  \"\"\"Constructs a random TT matrix with entrywise variance 1.0 / n_in\n","\n","  Args:\n","    shape: 2d array, shape[0] is the shape of the matrix row-index,\n","      shape[1] is the shape of the column index.\n","      shape[0] and shape[1] should have the same number of elements (d)\n","      Also supports omitting one of the dimensions for vectors, e.g.\n","        lecun_initializer([[2, 2, 2], None])\n","      and\n","        lecun_initializer([None, [2, 2, 2]])\n","      will create an 8-element column and row vectors correspondingly.\n","    tt_rank: a number or a (d+1)-element array with ranks.\n","    dtype: [tf.float32] dtype of the resulting matrix.\n","    name: string, name of the Op.\n","\n","  Returns:\n","    TensorTrain containing a TT-matrix of size\n","      np.prod(shape[0]) x np.prod(shape[1])\n","  \"\"\"\n","\n","  # In case the shape is immutable.\n","  shape = list(shape)\n","  # In case shape represents a vector, e.g. [None, [2, 2, 2]]\n","  if shape[0] is None:\n","    shape[0] = np.ones(len(shape[1]), dtype=int)\n","  # In case shape represents a vector, e.g. [[2, 2, 2], None]\n","  if shape[1] is None:\n","    shape[1] = np.ones(len(shape[0]), dtype=int)\n","  shape = np.array(shape)\n","  tt_rank = np.array(tt_rank)\n","  _validate_input_parameters(is_tensor=False, shape=shape, tt_rank=tt_rank)\n","  n_in = np.prod(shape[0])\n","  lamb = 1.0 / n_in\n","  with tf.name_scope(name):\n","    return random_matrix(shape, tt_rank=tt_rank, stddev=np.sqrt(lamb),\n","                         dtype=dtype)\n","\n"]}],"source":["import os\n","import t3f\n","\n","# Ruta específica al archivo __init__.py\n","t3f_initializers_path = '/usr/local/lib/python3.11/dist-packages/t3f/initializers.py'\n","\n","# Verificar si el archivo existe y mostrar su contenido\n","if os.path.exists(t3f_initializers_path):\n","    print(f\"Contenido del archivo {t3f_initializers_path}:\\n\")\n","    with open(t3f_initializers_path, 'r') as f:\n","        content = f.read()\n","        print(content)\n","else:\n","    print(f\"El archivo {t3f_initializers_path} no existe o no es accesible.\")"]},{"cell_type":"markdown","id":"1a848567","metadata":{"id":"1a848567"},"source":["---"]},{"cell_type":"markdown","id":"0ac8d565","metadata":{"id":"0ac8d565"},"source":["# Auxiliary functions (**IMPORTANT**)"]},{"cell_type":"code","execution_count":null,"id":"21a0fa77","metadata":{"id":"21a0fa77"},"outputs":[],"source":["import tensorflow as tf\n","import t3f\n","import functools\n","import numpy as np\n","\n","def objective_function(X, A, Omega):\n","    X_projected = t3f.gather_nd(X, Omega)  # Correct: use t3f.gather_nd for TensorTrain\n","    A_projected = tf.gather(A, tf.range(tf.shape(Omega)[0]))\n","    Z = X_projected - A_projected\n","\n","    # Compute inner product of Z with itself\n","    inner_product_Z = tf.tensordot(Z, Z, axes=1)\n","\n","    return 0.5 * inner_product_Z\n","\n","# Automatic Riemannian gradient\n","def compute_riemannian_gradient_tf(X, A, Omega):\n","    X_ortho = t3f.orthogonalize_tt_cores(X, left_to_right=True)\n","    partial_obj_fn = functools.partial(objective_function, A=A, Omega=Omega)\n","    gradient = t3f.gradients(partial_obj_fn, X_ortho, runtime_check=False)\n","    return gradient  # Returns a TensorTrain object\n","\n","def linearized_search(A_Omega, X_k, eta_k, Omega):\n","    X_k_proj = t3f.gather_nd(X_k, Omega)\n","    eta_k_proj = t3f.gather_nd(eta_k, Omega)\n","\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    diff = A_Omega - X_k_proj\n","\n","    numerator = tf.tensordot(eta_k_proj, diff, axes=1)\n","    denominator = tf.tensordot(eta_k_proj, eta_k_proj, axes=1)\n","\n","    alpha_k = numerator / denominator\n","    return alpha_k\n","\n","def increase_tt_rank_mu(tt_tensor, mu, noise_magnitude=1e-8):\n","    \"\"\"\n","    Increases the TT-rank at position mu+1 following algorithm (4.7).\n","\n","    Args:\n","        tt_tensor (t3f.TensorTrain): Tensor in Tensor Train format.\n","        mu (int): Index where the rank is increased. Valid values: mu = 1,...,d-1\n","        noise_magnitude (float, optional): Magnitude of random vectors R_mu and R_{mu+1}. Default = 1e-8.\n","\n","    Returns:\n","        t3f.TensorTrain: TT tensor with increased rank at position mu+1.\n","    \"\"\"\n","    tt_ortho = t3f.orthogonalize_tt_cores(tt_tensor, left_to_right=True)\n","    tt_cores = tt_ortho.tt_cores\n","    U_L = tt_cores[mu - 1]\n","    U_R = tt_cores[mu]\n","\n","    tt_ranks = t3f.tt_ranks(tt_tensor)\n","    r_mu_minus_1 = tt_ranks[mu - 1]\n","    r_mu = tt_ranks[mu]\n","    r_mu_plus_1 = tt_ranks[mu + 1]\n","\n","    n_mu = tt_tensor.get_shape()[mu - 1]\n","    n_mu_plus_1 = tt_tensor.get_shape()[mu]\n","\n","    R_mu = tf.random.normal([r_mu_minus_1 * n_mu, 1], mean=0.0, stddev=noise_magnitude)\n","    R_mu_plus_1 = tf.random.normal([1, r_mu_plus_1 * n_mu_plus_1], mean=0.0, stddev=noise_magnitude)\n","\n","    R_mu = tf.reshape(R_mu, [r_mu_minus_1, n_mu, 1])\n","    R_mu_plus_1 = tf.reshape(R_mu_plus_1, [1, n_mu_plus_1, r_mu_plus_1])\n","\n","    U_L_new = tf.concat([U_L, R_mu], axis=2)\n","    U_R_new = tf.concat([U_R, R_mu_plus_1], axis=0)\n","\n","    new_cores = tt_cores[:mu - 1] + (U_L_new, U_R_new) + tt_cores[mu + 1:]\n","\n","    return t3f.TensorTrain(new_cores)\n","\n","def truncate(tensor, target_ranks):\n","    \"\"\"Truncates a TT tensor to the target TT-ranks.\"\"\"\n","    return t3f.round(tensor, max_tt_rank=target_ranks)\n","\n","def riemannian_tensor_completion(X_0, A_Omega, Omega, max_iters=10, verbose=False):\n","    X_k = t3f.orthogonalize_tt_cores(X_0, left_to_right=True)\n","    target_ranks = t3f.tt_ranks(X_0).numpy()\n","\n","    xi_0 = compute_riemannian_gradient_tf(X_k, A_Omega, Omega)\n","    eta_0 = -xi_0\n","    alpha_0 = linearized_search(A_Omega, X_k, eta_0, Omega)\n","\n","    X_temp = X_k + alpha_0 * eta_0\n","    X_k = t3f.orthogonalize_tt_cores(truncate(X_temp, target_ranks), left_to_right=True)\n","\n","    xi_prev = xi_0\n","    eta_prev = eta_0\n","    ip_xi_xi_old = t3f.frobenius_norm_squared(xi_0)\n","\n","    for k in range(1, max_iters + 1):\n","        xi_k = compute_riemannian_gradient_tf(X_k, A_Omega, Omega)\n","        ip_xi_xi = t3f.frobenius_norm_squared(xi_k)\n","\n","        eta_transported = t3f.project(eta_prev, X_k)\n","        beta_k = ip_xi_xi / ip_xi_xi_old if ip_xi_xi_old != 0 else 0\n","\n","        eta_transported = truncate(eta_transported, target_ranks)\n","        eta_k = -xi_k + beta_k * eta_transported\n","        eta_k = truncate(eta_k, target_ranks)\n","\n","        alpha_k = linearized_search(A_Omega, X_k, eta_k, Omega)\n","        X_temp = X_k + alpha_k * eta_k\n","        X_k = t3f.orthogonalize_tt_cores(truncate(X_temp, target_ranks), left_to_right=True)\n","\n","        xi_prev = xi_k\n","        eta_prev = eta_k\n","        ip_xi_xi_old = ip_xi_xi\n","\n","    return X_k\n","\n","def chebyshev_nodes(n):\n","    \"\"\"\n","    Generate Chebyshev nodes of the first kind in the interval [0, 1].\n","\n","    Parameters:\n","    - n (int): Number of intervals (number of nodes will be n + 1).\n","\n","    Returns:\n","    - np.array: Array of (n + 1) Chebyshev nodes in [0, 1].\n","    \"\"\"\n","    k = np.arange(n + 1)\n","    q = np.cos(np.pi * k / n)\n","    x = (q + 1) / 2\n","    return x\n","\n","def make_omega_set(n_nodes, size, d):\n","    \"\"\"\n","    Generate a set of random multi-indices with d components, each between 0 and n_nodes - 1.\n","\n","    Parameters:\n","    - n_nodes (int): Number of discrete points per dimension.\n","    - size (int): Number of multi-indices to generate.\n","    - d (int): Number of dimensions.\n","\n","    Returns:\n","    - np.array: 2D array of shape (size, d) with random multi-indices.\n","    \"\"\"\n","    if n_nodes < 1:\n","        raise ValueError(\"n_nodes must be positive\")\n","    if size < 0:\n","        raise ValueError(\"size must be non-negative\")\n","\n","    total_combinations = n_nodes ** d\n","    if size > total_combinations:\n","        raise ValueError(f\"Requested size ({size}) exceeds total possible combinations ({total_combinations})\")\n","\n","    Omega = np.random.randint(0, n_nodes, size=(size, d))\n","    return Omega\n","\n","def map_to_chebyshev_nodes(Omega, n_nodes):\n","    \"\"\"\n","    Map multi-indices from range [0, n_nodes - 1] to Chebyshev nodes in [0, 1] for each dimension.\n","\n","    Parameters:\n","    - Omega: 2D NumPy array of shape (size, d) with multi-indices.\n","    - n_nodes: Number of Chebyshev nodes per dimension.\n","\n","    Returns:\n","    - 2D NumPy array of shape (size, d) with mapped Chebyshev nodes.\n","    \"\"\"\n","    if n_nodes < 1:\n","        raise ValueError(\"n_nodes must be positive\")\n","\n","    cheb_nodes = chebyshev_nodes(n_nodes - 1)\n","    d = Omega.shape[1]\n","    Omega_mapped = np.zeros_like(Omega, dtype=float)\n","    for dim in range(d):\n","        Omega_mapped[:, dim] = cheb_nodes[Omega[:, dim]]\n","\n","    return Omega_mapped\n","\n","def infer_input_dimension(f_vectorized, max_dimension=100):\n","    \"\"\"\n","    Try to infer the input dimension of a vectorized function f.\n","\n","    Parameters:\n","    - f_vectorized (callable): A function that takes input of shape (n_samples, d).\n","    - max_dimension (int): Maximum dimension to try.\n","\n","    Returns:\n","    - int or None: Inferred input dimension, or None if not found.\n","    \"\"\"\n","    for d in range(1, max_dimension + 1):\n","        try:\n","            test_input = np.zeros((1, d))\n","            f_vectorized(test_input)\n","            return d\n","        except (ValueError, IndexError):\n","            continue\n","        except Exception:\n","            return None\n","    return None\n","\n","def generate_disjoint_omega_c(Omega, sizeOmega_C, number_nodes):\n","    \"\"\"\n","    Generate a disjoint set Omega_C of the specified size.\n","\n","    Parameters:\n","    - Omega (array): Existing indices.\n","    - sizeOmega_C (int): Number of disjoint indices to generate.\n","    - number_nodes (int): Number of discrete values per dimension.\n","\n","    Returns:\n","    - np.array: Array of shape (sizeOmega_C, d) with disjoint indices.\n","    \"\"\"\n","    sizeOmega = len(Omega)\n","    d = Omega.shape[1]\n","\n","    if sizeOmega_C > number_nodes ** d - sizeOmega:\n","        raise ValueError(\"sizeOmega_C is too large to generate disjoint multi-indices\")\n","\n","    Omega = Omega.numpy() if isinstance(Omega, tf.Tensor) else Omega\n","    Omega_set = set(map(tuple, Omega))\n","\n","    Omega_C = []\n","    candidates_per_batch = int(sizeOmega_C * 1.5)\n","    attempts = 0\n","    max_attempts = 10\n","\n","    while len(Omega_C) < sizeOmega_C and attempts < max_attempts:\n","        candidates = np.random.randint(0, number_nodes, size=(candidates_per_batch, d))\n","        for idx in candidates:\n","            idx_tuple = tuple(idx)\n","            if idx_tuple not in Omega_set and idx_tuple not in {tuple(x) for x in Omega_C}:\n","                Omega_C.append(idx)\n","                if len(Omega_C) >= sizeOmega_C:\n","                    break\n","        attempts += 1\n","\n","    if len(Omega_C) < sizeOmega_C:\n","        raise ValueError(f\"Could not generate {sizeOmega_C} disjoint indices after {max_attempts} attempts\")\n","\n","    return np.array(Omega_C)"]},{"cell_type":"markdown","id":"0b3fb462","metadata":{"id":"0b3fb462"},"source":["In the next cell, we modify `adaptive_rank_strategy_Glau_fast` so that, in addition to the test set error, it also computes the training set error at each iteration (to check whether increasing the TT-rank helps reduce it).\n","\n","Note that if it doesn’t even fit the training set properly, the model likely needs more complexity (higher TT-rank), and the acceptance criterion may be too strict.\n","\n","I will also include the logic of `allow_error_augmentation` here."]},{"cell_type":"code","execution_count":null,"id":"906679c4","metadata":{"id":"906679c4"},"outputs":[],"source":["def adaptive_rank_strategy_Glau_fast(Omega, A_Omega, Omega_C, A_Omega_C, shape,\n","                                     max_rank, rank_initial, verbose,\n","                                     initial_guess=False, X_initial=None,\n","                                     max_iters=10, rho=1e-4,\n","                                     allow_error_augmentation=False):\n","    \"\"\"\n","    Fast adaptive TT-rank strategy based on Steinlechner's Riemannian optimization paper.\n","    Evaluates training (Omega) and validation (Omega_C) errors at each iteration.\n","    Supports two rank increase acceptance criteria based on allow_error_augmentation.\n","\n","    Parameters:\n","        Omega (np.ndarray): Indices of observed entries for training.\n","        A_Omega (np.ndarray): Values of observed training entries.\n","        Omega_C (np.ndarray): Validation/test indices.\n","        A_Omega_C (np.ndarray): Validation/test values.\n","        shape (tuple): Shape of the full tensor.\n","        max_rank (int): Maximum allowed TT-rank.\n","        rank_initial (int): Initial TT-rank used for random initialization.\n","        verbose (bool): If True, prints training progress.\n","        initial_guess (bool): Whether to use a custom initial tensor.\n","        X_initial (t3f.TensorTrain): Initial TT tensor (if initial_guess=True).\n","        max_iters (int): Max iterations for Riemannian CG.\n","        rho (float): Threshold for accepting rank increase.\n","        allow_error_augmentation (bool): Whether to allow error to increase slightly.\n","\n","    Returns:\n","        tuple: (X, errors) where\n","            - X is the completed TT tensor,\n","            - errors is a list of validation set errors at each accepted rank update.\n","    \"\"\"\n","    Omega = tf.constant(Omega, dtype=tf.int32)\n","    Omega_C = tf.constant(Omega_C, dtype=tf.int32)\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    A_Omega_C = tf.constant(A_Omega_C, dtype=tf.float32)\n","\n","    d = len(shape)\n","\n","    if initial_guess:\n","        if X_initial is None:\n","            raise ValueError(\"X_initial must be provided when initial_guess=True.\")\n","        X = X_initial\n","    else:\n","        initial_tt_rank = [1] + [rank_initial] * (d - 1) + [1]\n","        X = t3f.random_tensor(shape, tt_rank=initial_tt_rank)\n","\n","    X = riemannian_tensor_completion(X, A_Omega, Omega, max_iters=max_iters, verbose=verbose)\n","\n","    X_Omega_C = t3f.gather_nd(X, Omega_C)\n","    norm_A_C = np.linalg.norm(A_Omega_C.numpy())\n","    error_val = np.linalg.norm(A_Omega_C.numpy() - X_Omega_C.numpy()) / norm_A_C\n","\n","    X_Omega = t3f.gather_nd(X, Omega)\n","    norm_A = np.linalg.norm(A_Omega.numpy())\n","    error_train = np.linalg.norm(A_Omega.numpy() - X_Omega.numpy()) / norm_A\n","\n","    if verbose:\n","        print(f\"Initial validation error: {error_val:.6f}\")\n","        print(f\"Initial training error: {error_train:.6f}\")\n","\n","    errors = [error_val]\n","    locked = 0\n","    mu = 1\n","\n","    while locked < d - 1 and max(t3f.tt_ranks(X).numpy()[1:d]) < max_rank:\n","        ranks = t3f.tt_ranks(X).numpy()\n","\n","        if ranks[mu] < max_rank:\n","            X_new = increase_tt_rank_mu(X, mu)\n","            X_new = riemannian_tensor_completion(X_new, A_Omega, Omega, max_iters=max_iters, verbose=verbose)\n","\n","            X_new_Omega_C = t3f.gather_nd(X_new, Omega_C)\n","            error_val_new = np.linalg.norm(A_Omega_C.numpy() - X_new_Omega_C.numpy()) / norm_A_C\n","\n","            X_new_Omega = t3f.gather_nd(X_new, Omega)\n","            error_train_new = np.linalg.norm(A_Omega.numpy() - X_new_Omega.numpy()) / norm_A\n","\n","            if verbose:\n","                print(f\"mu={mu}: New validation error = {error_val_new:.6f}\")\n","                print(f\"mu={mu}: New training error = {error_train_new:.6f}\")\n","\n","            if allow_error_augmentation:\n","                accept = error_train_new <= error_train + rho\n","            else:\n","                accept = error_train_new < error_train - rho\n","\n","            if accept:\n","                X = X_new\n","                error_val = error_val_new\n","                error_train = error_train_new\n","                errors.append(error_val)\n","                locked = 0\n","                if verbose:\n","                    print(f\"Rank increase accepted at mu={mu}.\")\n","            else:\n","                locked += 1\n","                if verbose:\n","                    print(f\"Rank increase rejected at mu={mu}.\")\n","        else:\n","            locked += 1\n","            if verbose:\n","                print(f\"Rank at mu={mu} is already at max.\")\n","\n","        mu = (mu % (d - 1)) + 1\n","\n","    if verbose:\n","        print(f\"Final validation error: {error_val:.6f}\")\n","        print(f\"Final training error: {error_train:.6f}\")\n","\n","    return X, errors"]},{"cell_type":"markdown","id":"7554bb30","metadata":{"id":"7554bb30"},"source":["---"]},{"cell_type":"markdown","id":"7ec6f4cb","metadata":{"id":"7ec6f4cb"},"source":["# Complete tensor completion algorithm\n","\n","This cell implements Algorithm 1 from the adaptive sampling paper."]},{"cell_type":"code","execution_count":null,"id":"52bd3ac4","metadata":{"id":"52bd3ac4"},"outputs":[],"source":["def adaptive_sampling_strategy_1_v2(f_vectorized, sizeOmega, sizeOmega_C, number_nodes,\n","                                    rank_initial, max_rank, p=0.2,\n","                                    tol_1=1e-4, tol_2=1e-8,\n","                                    max_iters=10, rho=1e-4,\n","                                    verbose=False, allow_error_augmentation=False):\n","    \"\"\"\n","    Adaptive sampling strategy for tensor completion.\n","    At each stage, refines the solution using additional samples and updates the training set.\n","\n","    Parameters:\n","        f_vectorized (callable): Function to interpolate (vectorized).\n","        sizeOmega (int): Initial training set size.\n","        sizeOmega_C (int): Validation set size.\n","        number_nodes (int): Number of nodes per dimension.\n","        rank_initial (int): Initial TT-rank.\n","        max_rank (int): Maximum TT-rank allowed.\n","        p (float): Max percentage of observed entries vs full tensor size.\n","        tol_1 (float): Tolerance on absolute error (stopping criterion).\n","        tol_2 (float): Tolerance on error change between iterations.\n","        max_iters (int): Max Riemannian CG iterations.\n","        rho (float): Rank increase acceptance threshold.\n","        verbose (bool): If True, print logs.\n","        allow_error_augmentation (bool): If True, allows slight error increase when updating rank.\n","\n","    Returns:\n","        t3f.TensorTrain: The final approximated TT tensor.\n","    \"\"\"\n","    d = infer_input_dimension(f_vectorized)\n","    n = number_nodes * np.ones(d, dtype=int)\n","    shape = tuple(n)\n","\n","    Omega = make_omega_set(number_nodes, sizeOmega, d)\n","    Omega_mapped = map_to_chebyshev_nodes(Omega, number_nodes)\n","    Omega_C = generate_disjoint_omega_c(Omega, sizeOmega_C, number_nodes)\n","    Omega_C_mapped = map_to_chebyshev_nodes(Omega_C, number_nodes)\n","\n","    A_Omega = f_vectorized(Omega_mapped)\n","    A_Omega_C = f_vectorized(Omega_C_mapped)\n","\n","    Omega = tf.constant(Omega, dtype=tf.int32)\n","    Omega_C = tf.constant(Omega_C, dtype=tf.int32)\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    A_Omega_C = tf.constant(A_Omega_C, dtype=tf.float32)\n","\n","    X_c, _ = adaptive_rank_strategy_Glau_fast(Omega, A_Omega, Omega_C, A_Omega_C,\n","                                              shape, max_rank, rank_initial,\n","                                              verbose=verbose, initial_guess=False,\n","                                              max_iters=max_iters, rho=rho,\n","                                              allow_error_augmentation=allow_error_augmentation)\n","\n","    X_C_eval = t3f.gather_nd(X_c, Omega_C)\n","    err_new = np.linalg.norm(A_Omega_C.numpy() - X_C_eval.numpy()) / np.linalg.norm(A_Omega_C.numpy())\n","    if verbose:\n","        print(f\"Iteration 0: |Omega| = {len(Omega)}, Validation error = {err_new:.6f}\")\n","\n","    iteration = 0\n","    while len(Omega) / np.prod(shape) < p:\n","        iteration += 1\n","        err_old = err_new\n","\n","        Omega_C_old = Omega_C\n","        A_Omega_C_old = A_Omega_C\n","\n","        Omega_C = generate_disjoint_omega_c(Omega_C_old, sizeOmega_C, number_nodes)\n","        Omega_C_mapped = map_to_chebyshev_nodes(Omega_C, number_nodes)\n","        A_Omega_C = f_vectorized(Omega_C_mapped)\n","\n","        Omega_C = tf.constant(Omega_C, dtype=tf.int32)\n","        A_Omega_C = tf.constant(A_Omega_C, dtype=tf.float32)\n","\n","        Omega = tf.concat([Omega, Omega_C_old], axis=0)\n","        A_Omega = tf.concat([A_Omega, A_Omega_C_old], axis=0)\n","\n","        print(f\"Iteration {iteration}: |Omega| = {tf.shape(Omega)[0].numpy()}\")\n","\n","        X_c, _ = adaptive_rank_strategy_Glau_fast(Omega, A_Omega, Omega_C, A_Omega_C,\n","                                                  shape, max_rank, rank_initial,\n","                                                  verbose=verbose, initial_guess=True,\n","                                                  X_initial=X_c, max_iters=max_iters,\n","                                                  rho=rho,\n","                                                  allow_error_augmentation=allow_error_augmentation)\n","\n","        X_C_eval = t3f.gather_nd(X_c, Omega_C)\n","        err_new = np.linalg.norm(A_Omega_C.numpy() - X_C_eval.numpy()) / np.linalg.norm(A_Omega_C.numpy())\n","\n","        tt_ranks = t3f.tt_ranks(X_c)\n","        rank_max_reached = any(r >= max_rank for r in tt_ranks[1:-1])\n","\n","        if verbose:\n","            print(f\"Iteration {iteration}: |Omega| = {len(Omega)}, Validation error = {err_new:.6f}, TT-ranks = {tt_ranks.numpy()}\")\n","\n","        if (err_new < tol_1 or abs(err_new - err_old) < tol_2 or rank_max_reached):\n","            break\n","\n","    return X_c"]},{"cell_type":"markdown","id":"9c85d277","metadata":{"id":"9c85d277"},"source":["---"]},{"cell_type":"markdown","id":"6c3e5fcd","metadata":{"id":"6c3e5fcd"},"source":["# Test 1 (simple function from the paper)"]},{"cell_type":"markdown","id":"3c40dfe5","metadata":{"id":"3c40dfe5"},"source":["The next cell defines the function to be interpolated. This specific function is used in Glau’s paper as a first experiment in tensor completion, but for our purposes it is too simple."]},{"cell_type":"code","execution_count":null,"id":"17e4b002","metadata":{"id":"17e4b002"},"outputs":[],"source":["np.random.seed(610014)\n","tf.random.set_seed(610014)"]},{"cell_type":"code","execution_count":null,"id":"d24e5ee8","metadata":{"id":"d24e5ee8"},"outputs":[],"source":["def f_vectorized(X):\n","    \"\"\"\n","    Función f(x) = exp(-||x||), donde x es un vector en [0,1]^4.\n","    X: array de forma (N, 4), donde N es el número de puntos.\n","    Retorna: array de forma (N,) con los valores de la función.\n","    \"\"\"\n","    if X.shape[1] != 4:\n","        raise ValueError(\"La función espera entradas de dimensión 4\")\n","    norm_x = np.linalg.norm(X, axis=1)  # Norma euclidiana a lo largo de la dimensión de los puntos\n","    return np.exp(-norm_x)"]},{"cell_type":"markdown","id":"cbef53a9","metadata":{"id":"cbef53a9"},"source":["The following cell sets the parameters for running the algorithm (for this specific function) and executes the code."]},{"cell_type":"code","execution_count":null,"id":"e13a49d3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e13a49d3","outputId":"beb8fb77-a6e8-4773-e6f6-89de26403a54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error inicial en Omega_C: 1.057932\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.376843\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 1 2 1 1]\n","Aumento en mu=2: error_X_new = 1.760152\n","Aumento de rango rechazado para mu=2. Locked: 2\n","Aumento en mu=3: Rango TT de X_new: [1 1 1 2 1]\n","Aumento en mu=3: error_X_new = 1.270101\n","Aumento de rango rechazado para mu=3. Locked: 3\n","Error final en Omega_C: 1.057932\n","Iteración 0: |Omega| = 1600, Error en Omega_C = 1.057932\n","Iteración 1: Tamaño de Omega = 3600\n","Error inicial en Omega_C: 1.048903\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.417135\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 1 2 1 1]\n","Aumento en mu=2: error_X_new = 1.382957\n","Aumento de rango rechazado para mu=2. Locked: 2\n","Aumento en mu=3: Rango TT de X_new: [1 1 1 2 1]\n","Aumento en mu=3: error_X_new = 1.422563\n","Aumento de rango rechazado para mu=3. Locked: 3\n","Error final en Omega_C: 1.048903\n","Iteración 1: |Omega| = 3600, Error en Omega_C = 1.048903, Rango TT = [1 1 1 1 1]\n","Iteración 2: Tamaño de Omega = 5600\n","Error inicial en Omega_C: 1.011288\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.031068\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 1 2 1 1]\n","Aumento en mu=2: error_X_new = 1.212575\n","Aumento de rango rechazado para mu=2. Locked: 2\n","Aumento en mu=3: Rango TT de X_new: [1 1 1 2 1]\n","Aumento en mu=3: error_X_new = 1.114606\n","Aumento de rango rechazado para mu=3. Locked: 3\n","Error final en Omega_C: 1.011288\n","Iteración 2: |Omega| = 5600, Error en Omega_C = 1.011288, Rango TT = [1 1 1 1 1]\n","Iteración 3: Tamaño de Omega = 7600\n","Error inicial en Omega_C: 1.104254\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.090186\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 2 2 1 1]\n","Aumento en mu=2: error_X_new = 1.314866\n","Aumento de rango rechazado para mu=2. Locked: 1\n","Aumento en mu=3: Rango TT de X_new: [1 2 1 2 1]\n","Aumento en mu=3: error_X_new = 1.144761\n","Aumento de rango rechazado para mu=3. Locked: 2\n","Aumento en mu=1: Rango TT de X_new: [1 3 1 1 1]\n","Aumento en mu=1: error_X_new = 1.080941\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 3 2 1 1]\n","Aumento en mu=2: error_X_new = 1.102734\n","Aumento de rango rechazado para mu=2. Locked: 1\n","Aumento en mu=3: Rango TT de X_new: [1 3 1 2 1]\n","Aumento en mu=3: error_X_new = 1.147939\n","Aumento de rango rechazado para mu=3. Locked: 2\n","Aumento en mu=1: Rango TT de X_new: [1 4 1 1 1]\n","Aumento en mu=1: error_X_new = 1.098080\n","Aumento de rango rechazado para mu=1. Locked: 3\n","Error final en Omega_C: 1.080941\n","Iteración 3: |Omega| = 7600, Error en Omega_C = 1.080941, Rango TT = [1 3 1 1 1]\n","Iteración 4: Tamaño de Omega = 9600\n","Error inicial en Omega_C: 1.016986\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.022991\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 1 2 1 1]\n","Aumento en mu=2: error_X_new = 1.039735\n","Aumento de rango rechazado para mu=2. Locked: 2\n","Aumento en mu=3: Rango TT de X_new: [1 1 1 2 1]\n","Aumento en mu=3: error_X_new = 1.022499\n","Aumento de rango rechazado para mu=3. Locked: 3\n","Error final en Omega_C: 1.016986\n","Iteración 4: |Omega| = 9600, Error en Omega_C = 1.016986, Rango TT = [1 1 1 1 1]\n","Iteración 5: Tamaño de Omega = 11600\n","Error inicial en Omega_C: 1.364724\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.356174\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 2 2 1 1]\n","Aumento en mu=2: error_X_new = 2.965518\n","Aumento de rango rechazado para mu=2. Locked: 1\n","Aumento en mu=3: Rango TT de X_new: [1 2 1 2 1]\n","Aumento en mu=3: error_X_new = 2.120701\n","Aumento de rango rechazado para mu=3. Locked: 2\n","Aumento en mu=1: Rango TT de X_new: [1 3 1 1 1]\n","Aumento en mu=1: error_X_new = 1.383005\n","Aumento de rango rechazado para mu=1. Locked: 3\n","Error final en Omega_C: 1.356174\n","Iteración 5: |Omega| = 11600, Error en Omega_C = 1.356174, Rango TT = [1 2 1 1 1]\n","Iteración 6: Tamaño de Omega = 13600\n","Error inicial en Omega_C: 1.005303\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.076079\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 1 2 1 1]\n","Aumento en mu=2: error_X_new = 1.020200\n","Aumento de rango rechazado para mu=2. Locked: 2\n","Aumento en mu=3: Rango TT de X_new: [1 1 1 2 1]\n","Aumento en mu=3: error_X_new = 1.053862\n","Aumento de rango rechazado para mu=3. Locked: 3\n","Error final en Omega_C: 1.005303\n","Iteración 6: |Omega| = 13600, Error en Omega_C = 1.005303, Rango TT = [1 1 1 1 1]\n","Iteración 7: Tamaño de Omega = 15600\n","Error inicial en Omega_C: 1.145195\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 1.012482\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 2 2 1 1]\n","Aumento en mu=2: error_X_new = 0.522180\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 2 2 2 1]\n","Aumento en mu=3: error_X_new = 0.149433\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 3 2 2 1]\n","Aumento en mu=1: error_X_new = 0.180113\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 2 3 2 1]\n","Aumento en mu=2: error_X_new = 0.135405\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 2 3 3 1]\n","Aumento en mu=3: error_X_new = 0.096099\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 3 3 3 1]\n","Aumento en mu=1: error_X_new = 0.060986\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 3 4 3 1]\n","Aumento en mu=2: error_X_new = 0.052086\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 3 4 4 1]\n","Aumento en mu=3: error_X_new = 0.050988\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 4 4 4 1]\n","Aumento en mu=1: error_X_new = 0.049911\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 4 5 4 1]\n","Aumento en mu=2: error_X_new = 0.049605\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 4 5 5 1]\n","Aumento en mu=3: error_X_new = 0.049574\n","Aumento de rango rechazado para mu=3. Locked: 1\n","Aumento en mu=1: Rango TT de X_new: [1 5 5 4 1]\n","Aumento en mu=1: error_X_new = 0.049701\n","Aumento de rango rechazado para mu=1. Locked: 2\n","Aumento en mu=2: Rango TT de X_new: [1 4 6 4 1]\n","Aumento en mu=2: error_X_new = 0.049570\n","Aumento de rango rechazado para mu=2. Locked: 3\n","Error final en Omega_C: 0.049605\n","Iteración 7: |Omega| = 15600, Error en Omega_C = 0.049605, Rango TT = [1 4 5 4 1]\n","Iteración 8: Tamaño de Omega = 17600\n","Error inicial en Omega_C: 0.080490\n","Aumento en mu=1: Rango TT de X_new: [1 2 1 1 1]\n","Aumento en mu=1: error_X_new = 0.078869\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 2 2 1 1]\n","Aumento en mu=2: error_X_new = 0.061482\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 2 2 2 1]\n","Aumento en mu=3: error_X_new = 0.044582\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 3 2 2 1]\n","Aumento en mu=1: error_X_new = 0.009938\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 3 3 2 1]\n","Aumento en mu=2: error_X_new = 0.008821\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 3 3 3 1]\n","Aumento en mu=3: error_X_new = 0.002986\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 4 3 3 1]\n","Aumento en mu=1: error_X_new = 0.002479\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 4 4 3 1]\n","Aumento en mu=2: error_X_new = 0.001881\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 4 4 4 1]\n","Aumento en mu=3: error_X_new = 0.001484\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 5 4 4 1]\n","Aumento en mu=1: error_X_new = 0.000756\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [1 5 5 4 1]\n","Aumento en mu=2: error_X_new = 0.000470\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 5 5 5 1]\n","Aumento en mu=3: error_X_new = 0.000311\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=1: Rango TT de X_new: [1 6 5 5 1]\n","Aumento en mu=1: error_X_new = 0.000233\n","Aumento de rango rechazado para mu=1. Locked: 1\n","Aumento en mu=2: Rango TT de X_new: [1 5 6 5 1]\n","Aumento en mu=2: error_X_new = 0.000198\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [1 5 6 6 1]\n","Aumento en mu=3: error_X_new = 0.000153\n","Aumento de rango rechazado para mu=3. Locked: 1\n","Aumento en mu=1: Rango TT de X_new: [1 6 6 5 1]\n","Aumento en mu=1: error_X_new = 0.000156\n","Aumento de rango rechazado para mu=1. Locked: 2\n","Aumento en mu=2: Rango TT de X_new: [1 5 7 5 1]\n","Aumento en mu=2: error_X_new = 0.000184\n","Aumento de rango rechazado para mu=2. Locked: 3\n","Error final en Omega_C: 0.000198\n","Iteración 8: |Omega| = 17600, Error en Omega_C = 0.000198, Rango TT = [1 5 6 5 1]\n","Tensor completado X: A Tensor Train of shape (20, 20, 20, 20), TT-ranks: (1, 5, 6, 5, 1)\n","Rangos TT de X: tf.Tensor([1 5 6 5 1], shape=(5,), dtype=int32)\n"]}],"source":["# Probar el código\n","if __name__ == \"__main__\":\n","\n","    seed = 610015\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","    # Parámetros del algoritmo\n","    sizeOmega = 1600\n","    sizeOmega_C = 2000\n","    number_nodes = 20\n","    rank_initial = 1\n","    max_rank = 7\n","    p = 0.25\n","    tol_1 = 1e-3\n","    tol_2 = 1e-8\n","    max_iters = 10\n","    rho = 1e-4\n","    verbose = True\n","\n","    # Ejecutar el algoritmo\n","    X = adaptive_sampling_strategy_1(\n","        f_vectorized=f_vectorized,\n","        sizeOmega=sizeOmega,\n","        sizeOmega_C=sizeOmega_C,\n","        number_nodes=number_nodes,\n","        rank_initial=rank_initial,\n","        max_rank=max_rank,\n","        p=p,\n","        tol_1=tol_1,\n","        tol_2=tol_2,\n","        max_iters=max_iters,\n","        rho=rho,\n","        verbose=verbose\n","    )\n","\n","    print(\"Tensor completado X:\", X)\n","    print(\"Rangos TT de X:\", t3f.tt_ranks(X))"]},{"cell_type":"markdown","id":"cc082e4c","metadata":{"id":"cc082e4c"},"source":["We now compare some elements of the original tensor with those of the completed tensor (the approximation). Note that the code below materializes the full original tensor, which is not feasible in very high dimensions.\n","\n","For that, use `tf.gather_nd` or a similar method."]},{"cell_type":"code","execution_count":null,"id":"aac3bc34","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aac3bc34","outputId":"56df3162-ae0f-4c41-d7c7-245fbd402233"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original tensor shape: (20, 20, 20, 20)\n","Approximated tensor TT ranks: [1 5 4 4 1]\n","\n","Comparing 10 random samples:\n","Index                Original        Approximated    Abs Error      \n","-----------------------------------------------------------------\n","(4, 8, 8, 10)        0.262758        0.262748        0.000010       \n","(2, 15, 2, 0)        0.181922        0.182091        0.000169       \n","(14, 9, 9, 4)        0.304710        0.304680        0.000030       \n","(6, 1, 4, 1)         0.159435        0.159287        0.000148       \n","(7, 10, 18, 11)      0.399046        0.399309        0.000263       \n","(7, 16, 3, 17)       0.309078        0.309050        0.000028       \n","(2, 7, 5, 0)         0.169941        0.169673        0.000268       \n","(3, 5, 2, 4)         0.161103        0.160962        0.000141       \n","(17, 14, 15, 9)      0.562580        0.562705        0.000125       \n","(14, 7, 8, 9)        0.334692        0.334552        0.000140       \n","\n","Mean Absolute Error: 0.000132\n","Max Absolute Error: 0.000268\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import t3f\n","\n","# Assuming f_vectorized and adaptive_sampling_strategy_1 are defined as in your code\n","\n","def generate_full_chebyshev_tensor(f_vectorized, number_nodes):\n","    \"\"\"Generate the full tensor by evaluating f_vectorized on a Chebyshev grid.\"\"\"\n","    d = inferir_dimension_entrada(f_vectorized)\n","    cheb_nodes = chebyshev_nodes(number_nodes - 1)  # n_nodes - 1 intervals give n_nodes points\n","    grid = np.meshgrid(*[cheb_nodes] * d, indexing='ij')\n","    grid_flat = np.stack([g.flatten() for g in grid], axis=-1)  # Shape: (number_nodes^d, d)\n","    values = f_vectorized(grid_flat)  # Shape: (number_nodes^d,)\n","    return values.reshape([number_nodes] * d)  # Shape: (n, n, ..., n)\n","\n","def compare_random_samples(original_tensor, approx_tensor, N_samples):\n","    \"\"\"Compare N_samples random elements from original and approximated tensors.\"\"\"\n","    shape = original_tensor.shape\n","    d = len(shape)\n","    total_elements = np.prod(shape)\n","\n","    # Generate N_samples random multi-indices\n","    indices = np.random.randint(0, shape[0], size=(N_samples, d))\n","    indices_tf = tf.constant(indices, dtype=tf.int32)\n","\n","    # Extract values from original tensor (NumPy array)\n","    original_values = original_tensor[tuple(indices.T)]  # Shape: (N_samples,)\n","\n","    # Extract values from approximated TT tensor using t3f.gather_nd\n","    approx_values = t3f.gather_nd(approx_tensor, indices_tf).numpy()  # Shape: (N_samples,)\n","\n","    # Compute absolute errors\n","    abs_errors = np.abs(original_values - approx_values)\n","\n","    # Display comparison\n","    print(f\"\\nComparing {N_samples} random samples:\")\n","    print(f\"{'Index':<20} {'Original':<15} {'Approximated':<15} {'Abs Error':<15}\")\n","    print(\"-\" * 65)\n","    for i in range(N_samples):\n","        idx_tuple = tuple(int(idx) for idx in indices[i])  # Convert indices to standard integers\n","        idx_str = str(idx_tuple)\n","        print(f\"{idx_str:<20} {original_values[i]:<15.6f} {approx_values[i]:<15.6f} {abs_errors[i]:<15.6f}\")\n","\n","    # Summary statistics\n","    mean_abs_error = np.mean(abs_errors)\n","    max_abs_error = np.max(abs_errors)\n","    print(f\"\\nMean Absolute Error: {mean_abs_error:.6f}\")\n","    print(f\"Max Absolute Error: {max_abs_error:.6f}\")\n","\n","    return abs_errors\n","\n","N_samples = 10\n","\n","# Generate original tensor\n","original_tensor = generate_full_chebyshev_tensor(f_vectorized, number_nodes)\n","print(f\"Original tensor shape: {original_tensor.shape}\")\n","\n","# Run adaptive sampling strategy\n","X_approx = X\n","\n","print(f\"Approximated tensor TT ranks: {t3f.tt_ranks(X_approx).numpy()}\")\n","\n","# Compare random samples\n","errors = compare_random_samples(original_tensor, X_approx, N_samples)"]},{"cell_type":"markdown","id":"62db9e9a","metadata":{"id":"62db9e9a"},"source":["**IMPORTANT:** The stopping criterion that matters most for our purposes is the first one, so we should check whether it is properly defined. In principle, there’s no issue since it is defined exactly as in the paper, but we need to ensure that `tol_1` has a value that makes sense for our goals."]},{"cell_type":"markdown","id":"53672dcf","metadata":{"id":"53672dcf"},"source":["---"]},{"cell_type":"markdown","id":"a5b382ec","metadata":{"id":"a5b382ec"},"source":["# Test 2 ($f_1$)"]},{"cell_type":"markdown","id":"57fac94d","metadata":{"id":"57fac94d"},"source":["This is the $f_1$ function used in the Overleaf tests."]},{"cell_type":"code","execution_count":null,"id":"2bdd6fa0","metadata":{"id":"2bdd6fa0"},"outputs":[],"source":["def f_vectorized(x):\n","    \"\"\"\n","    Args:\n","        x (numpy.ndarray): Vector de 10 dimensiones.\n","\n","    Returns:\n","        float: Evaluación de la función.\n","    \"\"\"\n","    if len(x.shape) == 1:\n","        x = x.reshape(1, -1)\n","    num_samples, d = x.shape\n","    if d != 10:\n","        raise ValueError(\"Se requieren exactamente 10 dimensiones\")\n","\n","    return (x[:, 0] ** 2 + np.exp(x[:, 1]) + np.log(x[:, 2] + 1) +\n","            1 / (x[:, 3] + 1) + x[:, 4] ** 3 + np.sqrt(x[:, 5]) +\n","            x[:, 6] * x[:, 7] + x[:, 8] ** 4 - np.exp(-x[:, 9]))"]},{"cell_type":"code","execution_count":null,"id":"44c293db","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44c293db","outputId":"7ec54ae6-3fde-4031-929c-9166a5195494"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error inicial en Omega_C (prueba): 1.535708\n","Error inicial en Omega (entrenamiento): 0.195603\n","Aumento en mu=1: Rango TT de X_new: [ 1 11 10 10 10 10 10 10 10 10  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.531042\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.172301\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 11 11 10 10 10 10 10 10 10  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.504150\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.134824\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 11 11 11 10 10 10 10 10 10  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.554512\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.062608\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 11 11 11 11 10 10 10 10 10  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.549019\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.044919\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 11 11 11 11 11 10 10 10 10  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.554909\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.033450\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 11 11 11 11 11 11 10 10 10  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.553682\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.025521\n","Aumento de rango aceptado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 11 11 11 11 11 11 11 10 10  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.554590\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.023060\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 11 11 11 11 11 11 11 11 10  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.554620\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.022646\n","Aumento de rango aceptado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 11 11 11 11 11 11 11 11 11  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.554648\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.022511\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 12 11 11 11 11 11 11 11 11  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.554701\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.022425\n","Aumento de rango rechazado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 11 12 11 11 11 11 11 11 11  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.554749\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.022495\n","Aumento de rango rechazado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 11 11 12 11 11 11 11 11 11  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.554717\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.022301\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 11 11 12 12 11 11 11 11 11  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.554724\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.021815\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 11 11 12 12 12 11 11 11 11  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.554730\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.021741\n","Aumento de rango rechazado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 11 11 12 12 11 12 11 11 11  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.554728\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.021532\n","Aumento de rango aceptado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 11 11 12 12 11 12 12 11 11  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.021040\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 11 11 12 12 11 12 12 12 11  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.554817\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.019061\n","Aumento de rango aceptado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 11 11 12 12 11 12 12 12 12  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.554817\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.017847\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 12 11 12 12 11 12 12 12 12  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.554803\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.016716\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 12 12 12 12 11 12 12 12 12  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.554799\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.012950\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 12 12 13 12 11 12 12 12 12  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.554801\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.012312\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 12 12 13 13 11 12 12 12 12  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.554805\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.012020\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 12 12 13 13 12 12 12 12 12  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.554809\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.011834\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 12 12 13 13 12 13 12 12 12  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.011789\n","Aumento de rango rechazado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 12 12 13 13 12 12 13 12 12  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.554809\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.011755\n","Aumento de rango rechazado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 12 12 13 13 12 12 12 13 12  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.011753\n","Aumento de rango rechazado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 12 12 13 13 12 12 12 12 13  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.554813\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.011753\n","Aumento de rango rechazado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 13 12 13 13 12 12 12 12 12  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.011766\n","Aumento de rango rechazado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 12 13 13 13 12 12 12 12 12  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.554809\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.011764\n","Aumento de rango rechazado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 12 12 14 13 12 12 12 12 12  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.554809\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.011758\n","Aumento de rango rechazado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 12 12 13 14 12 12 12 12 12  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.011758\n","Aumento de rango rechazado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 12 12 13 13 13 12 12 12 12  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.554810\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.011761\n","Aumento de rango rechazado para mu=5.\n","Error final en Omega_C (prueba): 1.554809\n","Error final en Omega (entrenamiento): 0.011834\n","Iteración 0: |Omega| = 5000, Error en Omega_C = 1.554809\n","Iteración 1: Tamaño de Omega = 6000\n","Error inicial en Omega_C (prueba): 1.617376\n","Error inicial en Omega (entrenamiento): 0.569228\n","Aumento en mu=1: Rango TT de X_new: [ 1 13 12 13 13 12 12 12 12 12  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.612402\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.518358\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 13 13 13 13 12 12 12 12 12  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.602689\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.464260\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 13 13 14 13 12 12 12 12 12  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.600494\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.439449\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 13 13 14 14 12 12 12 12 12  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.598107\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.411867\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 13 13 14 14 13 12 12 12 12  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.597090\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.395952\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 13 13 14 14 13 13 12 12 12  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.596733\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.389296\n","Aumento de rango aceptado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 13 13 14 14 13 13 13 12 12  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.594014\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.384980\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 13 13 14 14 13 13 13 13 12  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.594466\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.345204\n","Aumento de rango aceptado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 13 13 14 14 13 13 13 13 13  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.608603\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.307124\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 14 13 14 14 13 13 13 13 13  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.605295\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.268029\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 14 14 14 14 13 13 13 13 13  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.608053\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.241947\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 14 14 15 14 13 13 13 13 13  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.607856\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.350742\n","Aumento de rango rechazado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 14 14 14 15 13 13 13 13 13  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.608363\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.227525\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 14 14 14 15 14 13 13 13 13  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.608749\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.223425\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 14 14 14 15 14 14 13 13 13  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.609473\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.220367\n","Aumento de rango aceptado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 14 14 14 15 14 14 14 13 13  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.609589\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.218735\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 14 14 14 15 14 14 14 14 13  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.609593\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.218714\n","Aumento de rango rechazado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 14 14 14 15 14 14 14 13 14  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.610001\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.216506\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 15 14 14 15 14 14 14 13 14  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.610083\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.215653\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 15 15 14 15 14 14 14 13 14  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.610201\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.215180\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 15 15 15 15 14 14 14 13 14  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.610244\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.214705\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 15 15 15 16 14 14 14 13 14  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.610297\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.213734\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 15 15 15 16 15 14 14 13 14  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.610301\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.213261\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 15 15 15 16 15 15 14 13 14  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.610305\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.213181\n","Aumento de rango rechazado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 15 15 15 16 15 14 15 13 14  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.610325\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.212553\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 15 15 15 16 15 14 15 14 14  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.610331\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.212207\n","Aumento de rango aceptado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 15 15 15 16 15 14 15 14 15  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.610339\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.211961\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 16 15 15 16 15 14 15 14 15  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.610346\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.211656\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 16 16 15 16 15 14 15 14 15  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.610360\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.210465\n","Aumento de rango aceptado para mu=2.\n","Aumento en mu=3: Rango TT de X_new: [ 1 16 16 16 16 15 14 15 14 15  1]\n","Aumento en mu=3: Error en Omega_C (prueba) = 1.610409\n","Aumento en mu=3: Error en Omega (entrenamiento) = 0.210097\n","Aumento de rango aceptado para mu=3.\n","Aumento en mu=4: Rango TT de X_new: [ 1 16 16 16 17 15 14 15 14 15  1]\n","Aumento en mu=4: Error en Omega_C (prueba) = 1.610418\n","Aumento en mu=4: Error en Omega (entrenamiento) = 0.209821\n","Aumento de rango aceptado para mu=4.\n","Aumento en mu=5: Rango TT de X_new: [ 1 16 16 16 17 16 14 15 14 15  1]\n","Aumento en mu=5: Error en Omega_C (prueba) = 1.610435\n","Aumento en mu=5: Error en Omega (entrenamiento) = 0.209048\n","Aumento de rango aceptado para mu=5.\n","Aumento en mu=6: Rango TT de X_new: [ 1 16 16 16 17 16 15 15 14 15  1]\n","Aumento en mu=6: Error en Omega_C (prueba) = 1.610438\n","Aumento en mu=6: Error en Omega (entrenamiento) = 0.208806\n","Aumento de rango aceptado para mu=6.\n","Aumento en mu=7: Rango TT de X_new: [ 1 16 16 16 17 16 15 16 14 15  1]\n","Aumento en mu=7: Error en Omega_C (prueba) = 1.610443\n","Aumento en mu=7: Error en Omega (entrenamiento) = 0.208693\n","Aumento de rango aceptado para mu=7.\n","Aumento en mu=8: Rango TT de X_new: [ 1 16 16 16 17 16 15 16 15 15  1]\n","Aumento en mu=8: Error en Omega_C (prueba) = 1.610442\n","Aumento en mu=8: Error en Omega (entrenamiento) = 0.208659\n","Aumento de rango rechazado para mu=8.\n","Aumento en mu=9: Rango TT de X_new: [ 1 16 16 16 17 16 15 16 14 16  1]\n","Aumento en mu=9: Error en Omega_C (prueba) = 1.610446\n","Aumento en mu=9: Error en Omega (entrenamiento) = 0.208530\n","Aumento de rango aceptado para mu=9.\n","Aumento en mu=1: Rango TT de X_new: [ 1 17 16 16 17 16 15 16 14 16  1]\n","Aumento en mu=1: Error en Omega_C (prueba) = 1.610461\n","Aumento en mu=1: Error en Omega (entrenamiento) = 0.207017\n","Aumento de rango aceptado para mu=1.\n","Aumento en mu=2: Rango TT de X_new: [ 1 17 17 16 17 16 15 16 14 16  1]\n","Aumento en mu=2: Error en Omega_C (prueba) = 1.610481\n","Aumento en mu=2: Error en Omega (entrenamiento) = 0.205924\n","Aumento de rango aceptado para mu=2.\n"]}],"source":["# Probar el código\n","if __name__ == \"__main__\":\n","\n","    seed = 610015\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","    # Parámetros del algoritmo\n","    sizeOmega = 5000\n","    sizeOmega_C = 1000\n","    number_nodes = 50\n","    rank_initial = 10\n","    max_rank = 20\n","    p = 0.25\n","    tol_1 = 1e-3\n","    tol_2 = 1e-8\n","    max_iters = 10\n","    rho = 1e-4\n","    verbose = True\n","    allow_error_augmentation = False\n","\n","    # Ejecutar el algoritmo\n","    X = adaptive_sampling_strategy_1_v2(\n","        f_vectorized=f_vectorized,\n","        sizeOmega=sizeOmega,\n","        sizeOmega_C=sizeOmega_C,\n","        number_nodes=number_nodes,\n","        rank_initial=rank_initial,\n","        max_rank=max_rank,\n","        p=p,\n","        tol_1=tol_1,\n","        tol_2=tol_2,\n","        max_iters=max_iters,\n","        rho=rho,\n","        verbose=verbose,\n","        allow_error_augmentation=allow_error_augmentation\n","    )\n","\n","    print(\"Tensor completado X:\", X)\n","    print(\"Rangos TT de X:\", t3f.tt_ranks(X))"]},{"cell_type":"markdown","id":"05bece74","metadata":{"id":"05bece74"},"source":["**Current behavior analysis:** In the first iteration of `adaptive_sampling_strategy_1`, the training set error does not decrease because the approximation tensor lacks sufficient complexity (TT-rank), since the rank increase acceptance criterion is too strict.\n","\n","As a result, all iterations of `adaptive_rank_strategy_Glau_fast` finish without improving the error on $\\Omega$ (training set), and the algorithm proceeds to increase the training set size. However, this approach is flawed, as the algorithm should first fit the small training set properly before expanding it.\n","\n","**Conclusion:** The algorithm needs a less strict stopping criterion."]},{"cell_type":"markdown","id":"124069fd","metadata":{"id":"124069fd"},"source":["Add an explicit counter for how many times the function $f_1$ is evaluated."]},{"cell_type":"markdown","id":"6f593972","metadata":{"id":"6f593972"},"source":["---"]},{"cell_type":"markdown","id":"3c5fc744","metadata":{"id":"3c5fc744"},"source":["# Test 3 ($f_2$)"]},{"cell_type":"code","execution_count":null,"id":"f562b791","metadata":{"id":"f562b791"},"outputs":[],"source":["def f_vectorized(x):\n","    \"\"\"\n","    Args:\n","        x (numpy.ndarray): Vector de 10 dimensiones.\n","\n","    Returns:\n","        float: Evaluación de la función f2.\n","    \"\"\"\n","    if len(x.shape) == 1:\n","        x = x.reshape(1, -1)\n","    num_samples, d = x.shape\n","    if d != 10:\n","        raise ValueError(\"Se requieren exactamente 10 dimensiones\")\n","\n","    return (x[:, 0]**2 * x[:, 6]**2 * x[:, 9]**2 * np.exp(-x[:, 1]**4 - x[:, 5] - x[:, 7] * x[:, 8]) +\n","            np.log(1 + x[:, 3] + x[:, 2] * x[:, 7]) +\n","            (x[:, 0]**2 + x[:, 1] + x[:, 4]) / (1 + x[:, 5]**3 + x[:, 2]**3 + x[:, 8]**4))\n","\n","# Probar el código\n","if __name__ == \"__main__\":\n","\n","    seed = 610015\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","    # Parámetros del algoritmo\n","    sizeOmega = 2000\n","    sizeOmega_C = 1000\n","    number_nodes = 50\n","    rank_initial = 12\n","    max_rank = 20\n","    p = 0.25\n","    tol_1 = 1e-3\n","    tol_2 = 1e-8\n","    max_iters = 10\n","    rho = 1e-4\n","    verbose = True\n","\n","    # Ejecutar el algoritmo\n","    X = adaptive_sampling_strategy_1(\n","        f_vectorized=f_vectorized,\n","        sizeOmega=sizeOmega,\n","        sizeOmega_C=sizeOmega_C,\n","        number_nodes=number_nodes,\n","        rank_initial=rank_initial,\n","        max_rank=max_rank,\n","        p=p,\n","        tol_1=tol_1,\n","        tol_2=tol_2,\n","        max_iters=max_iters,\n","        rho=rho,\n","        verbose=verbose\n","    )\n","\n","    print(\"Tensor completado X:\", X)\n","    print(\"Rangos TT de X:\", t3f.tt_ranks(X))"]},{"cell_type":"markdown","id":"b6f6d16f","metadata":{"id":"b6f6d16f"},"source":["---"]},{"cell_type":"markdown","id":"53fee4f4","metadata":{"id":"53fee4f4"},"source":["# All code in a single cell"]},{"cell_type":"code","execution_count":null,"id":"2df66d20","metadata":{"id":"2df66d20"},"outputs":[],"source":["import tensorflow as tf\n","import t3f\n","import functools\n","import numpy as np\n","\n","def funcion_objetivo(X, A, Omega):\n","    X_proyectado = t3f.gather_nd(X, Omega)  # Correcto: usar t3f.gather_nd para TensorTrain\n","    A_proyectado = tf.gather(A, tf.range(tf.shape(Omega)[0]))\n","    Z = X_proyectado - A_proyectado\n","\n","    # Calcular el producto escalar de Z consigo mismo\n","    producto_escalar_Z = tf.tensordot(Z, Z, axes=1)\n","\n","    return 0.5 * producto_escalar_Z\n","\n","# Gradiente Riemanniano automático\n","def calcular_gradiente_riemanniano_tf(X, A, Omega):\n","    X_ortho = t3f.orthogonalize_tt_cores(X, left_to_right=True)\n","    funcion_objetivo_parcial = functools.partial(funcion_objetivo, A=A, Omega=Omega)\n","    gradiente = t3f.gradients(funcion_objetivo_parcial, X_ortho, runtime_check=False)\n","    return gradiente # El resultado es un TensorTrain de t3f\n","\n","def linearized_search(A_Omega, X_k, eta_k, Omega):\n","    X_k_proyectado = t3f.gather_nd(X_k, Omega)\n","    eta_k_proyectado = t3f.gather_nd(eta_k, Omega)\n","\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    resta = A_Omega - X_k_proyectado\n","\n","    # Calcular el numerador y el denominador\n","    num = tf.tensordot(eta_k_proyectado, resta, axes=1)\n","    den = tf.tensordot(eta_k_proyectado, eta_k_proyectado, axes=1)\n","\n","    alpha_k = num / den\n","    return alpha_k\n","\n","def increase_tt_rank_mu(tt_tensor, mu, noise_magnitude=1e-8):\n","    \"\"\"\n","    Incrementa el rango TT en la posición mu+1 siguiendo el algoritmo (4.7).\n","\n","    Args:\n","        tt_tensor (t3f.TensorTrain): Tensor en formato TT.\n","        mu (int): Índice donde se incrementará el rango. Únicos valores posibles: mu = 1,...,d-1\n","        noise_magnitude(float, opcional): Magnitud de los vectores aleatorios R_mu y R_{mu+1}. Default = 1e-8.\n","\n","    Returns:\n","        t3f.TensorTrain: Tensor TT con rango aumentado en la posición mu+1.\n","    \"\"\"\n","    # Paso 1: Ortogonalizar desde la izquierda hasta la posición mu\n","    tt_ortho = t3f.orthogonalize_tt_cores(tt_tensor, left_to_right=True)\n","\n","    # Paso 2: Extraer núcleos TT\n","    tt_cores = tt_ortho.tt_cores  # Lista de núcleos TT. Esto es un tf.Tensor, por eso podemos usar .tt_cores\n","    U_L = tt_cores[mu-1]            # Núcleo en la posición mu\n","    U_R = tt_cores[mu]          # Núcleo en la posición mu+1\n","\n","    # Paso 3: Extraer el vector de rangos TT correctamente\n","    tt_ranks = t3f.tt_ranks(tt_tensor)\n","    r_mu_minus_1 = tt_ranks[mu-1]  # Rango TT en la posición mu-1\n","    r_mu = tt_ranks[mu]            # Rango TT en la posición mu\n","    r_mu_plus_1 = tt_ranks[mu+1]   # Rango TT en la posición mu+1\n","\n","    # Extraer las dimensiones de los modos\n","    n_mu = tt_tensor.get_shape()[mu-1]       # Dimensión en la posición mu\n","    n_mu_plus_1 = tt_tensor.get_shape()[mu]  # Dimensión en la posición mu+1\n","\n","    # Paso 4: Crear vectores aleatorios con la norma deseada\n","    R_mu = tf.random.normal(shape=[r_mu_minus_1 * n_mu, 1], mean=0.0, stddev=noise_magnitude)\n","    R_mu_plus_1 = tf.random.normal(shape=[1, r_mu_plus_1 * n_mu_plus_1], mean=0.0, stddev=noise_magnitude)\n","\n","    # Paso 5: Redimensionar los vectores para que sean compatibles con la estructura TT\n","    R_mu = tf.reshape(R_mu, [r_mu_minus_1, n_mu, 1])  # Convertir a (r_{mu-1}, n_mu, 1)\n","    R_mu_plus_1 = tf.reshape(R_mu_plus_1, [1, n_mu_plus_1, r_mu_plus_1])  # Convertir a (1, n_{mu+1}, r_{mu+1})\n","\n","    # Paso 6: Modificar los núcleos TT en las posiciones mu y mu+1\n","    U_L_new = tf.concat([U_L, R_mu], axis=2)  # Expandir en la tercera dimensión (r_mu+1)\n","    U_R_new = tf.concat([U_R, R_mu_plus_1], axis=0)  # Expandir en la primera dimensión (r_mu+1)\n","\n","    # Paso 7: Reconstruir la lista de núcleos con las modificaciones\n","    new_cores = tt_cores[:mu-1] + (U_L_new, U_R_new) + tt_cores[mu+1:]\n","\n","    # Mostrar la lista de cores y sus dimensiones (Opcional)\n","    # print(\"Lista de new_cores y sus dimensiones:\")\n","    # for i, core in enumerate(new_cores):\n","        # print(f\"Core {i}: Shape {core.shape}\")\n","\n","    # Paso 8: Crear el nuevo tensor TT con los núcleos modificados\n","    tt_tensor_updated = t3f.TensorTrain(new_cores)\n","\n","    return tt_tensor_updated\n","\n","def truncate(tensor, target_ranks):\n","    \"\"\"Trunca un tensor TT a los rangos objetivo.\"\"\"\n","    return t3f.round(tensor, max_tt_rank=target_ranks)\n","\n","def riemannian_tensor_completion(X_0, A_Omega, Omega, max_iters=10, verbose=False):\n","    X_k = t3f.orthogonalize_tt_cores(X_0, left_to_right=True)\n","\n","    target_ranks = t3f.tt_ranks(X_0).numpy()  # Rangos objetivo\n","\n","    xi_0 = calcular_gradiente_riemanniano_tf(X_k, A_Omega, Omega)\n","    eta_0 = -xi_0\n","    alpha_0 = linearized_search(A_Omega, X_k, eta_0, Omega)\n","\n","    X_temp = X_k + alpha_0 * eta_0\n","    X_k = t3f.orthogonalize_tt_cores(truncate(X_temp, target_ranks), left_to_right=True)\n","\n","    xi_k_anterior = xi_0\n","    eta_k_anterior = eta_0\n","    ip_xi_xi_old = t3f.frobenius_norm_squared(xi_0)\n","\n","    for k in range(1, max_iters + 1):\n","        xi_k = calcular_gradiente_riemanniano_tf(X_k, A_Omega, Omega)\n","        ip_xi_xi = t3f.frobenius_norm_squared(xi_k)\n","\n","        eta_transported = t3f.project(eta_k_anterior, X_k)  # Rangos 2r\n","        beta_k = ip_xi_xi / ip_xi_xi_old if ip_xi_xi_old != 0 else 0\n","\n","        eta_transported = truncate(eta_transported, target_ranks)\n","\n","        eta_k = -xi_k + beta_k * eta_transported  # Rangos 4r\n","        eta_k = truncate(eta_k, target_ranks)  # Truncar a rangos r\n","\n","        alpha_k = linearized_search(A_Omega, X_k, eta_k, Omega)\n","\n","        X_temp = X_k + alpha_k * eta_k  # Rangos 2r (r + r)\n","        X_k = t3f.orthogonalize_tt_cores(truncate(X_temp, target_ranks), left_to_right=True)\n","\n","        xi_k_anterior = xi_k\n","        eta_k_anterior = eta_k\n","        ip_xi_xi_old = ip_xi_xi\n","\n","    return X_k\n","\n","# Función para generar nodos de Chebyshev en el intervalo [0, 1]\n","def chebyshev_nodes(n):\n","    \"\"\"\n","    Generate Chebyshev nodes of the first kind in the interval [0, 1].\n","\n","    Parameters:\n","    - n (int): Number of intervals (number of nodes will be n + 1).\n","\n","    Returns:\n","    - np.array: Array of (n + 1) Chebyshev nodes in [0, 1].\n","    \"\"\"\n","    k = np.arange(n + 1)  # Indices 0 to n\n","    q = np.cos(np.pi * k / n)  # Nodos en [-1, 1]\n","    x = (q + 1) / 2  # Mapeo a [0, 1]\n","    return x\n","\n","# Función para generar un conjunto de índices aleatorios (0-based)\n","def make_omega_set(n_nodes, size, d):\n","    \"\"\"\n","    Generate a set of random multi-indices with d components, each between 0 and n_nodes - 1.\n","\n","    Parameters:\n","    - n_nodes (int): Upper bound for each index (range is 0 to n_nodes - 1).\n","    - size (int): Number of multi-indices to generate.\n","    - d (int): Number of dimensions.\n","\n","    Returns:\n","    - np.array: 2D array of shape (size, d) with random multi-indices.\n","    \"\"\"\n","    if n_nodes < 1:\n","        raise ValueError(\"n_nodes must be positive\")\n","    if size < 0:\n","        raise ValueError(\"size must be non-negative\")\n","\n","    total_combinations = n_nodes ** d\n","    if size > total_combinations:\n","        raise ValueError(f\"Requested size ({size}) exceeds total possible combinations ({total_combinations})\")\n","\n","    # Generate random multi-indices (0 to n_nodes - 1)\n","    Omega = np.random.randint(0, n_nodes, size=(size, d))\n","\n","    return Omega\n","\n","# Función para mapear índices a nodos de Chebyshev\n","def map_to_chebyshev_nodes(Omega, n_nodes):\n","    \"\"\"\n","    Map multi-indices from range [0, n_nodes - 1] to Chebyshev nodes in [0, 1] for each dimension.\n","\n","    Parameters:\n","    - Omega: 2D NumPy array of shape (size, d) with multi-indices.\n","    - n_nodes: Upper bound of the original indices (number of nodes per dimension).\n","\n","    Returns:\n","    - 2D NumPy array of shape (size, d) with values mapped to Chebyshev nodes.\n","    \"\"\"\n","    if n_nodes < 1:\n","        raise ValueError(\"n_nodes must be positive\")\n","\n","    # Precompute Chebyshev nodes for one dimension (n_nodes points)\n","    cheb_nodes = chebyshev_nodes(n_nodes - 1)  # n_nodes - 1 intervals give n_nodes points\n","\n","    # Map each index to the corresponding Chebyshev node\n","    d = Omega.shape[1]\n","    Omega_mapped = np.zeros_like(Omega, dtype=float)\n","    for dim in range(d):\n","        Omega_mapped[:, dim] = cheb_nodes[Omega[:, dim]]\n","\n","    return Omega_mapped\n","\n","def inferir_dimension_entrada(f_vectorized, max_dimension=100):\n","    \"\"\"\n","    Intenta inferir la dimensión de entrada de una función f_vectorized.\n","    \"\"\"\n","    for d in range(1, max_dimension + 1):\n","        try:\n","            # Crea una entrada de prueba con la dimensión d\n","            entrada_prueba = np.zeros((1, d))\n","\n","            # Intenta ejecutar la función\n","            f_vectorized(entrada_prueba)\n","\n","            # Si la función se ejecuta sin errores, la dimensión de entrada es d\n","            return d\n","        except ValueError:\n","            # Si se produce un ValueError, intenta con la siguiente dimensión\n","            pass\n","        except IndexError:\n","            pass\n","        except Exception:\n","            # Si se produce cualquier otro error, no se puede determinar la dimensión\n","            return None\n","\n","    # Si no se encontró una dimensión válida, devuelve None\n","    return None\n","\n","def generate_disjoint_omega_c(Omega, sizeOmega_C, number_nodes):\n","    \"\"\"\n","    Genera un conjunto Omega_C de tamaño sizeOmega_C con índices disjuntos de Omega.\n","    \"\"\"\n","    sizeOmega = len(Omega)\n","    d = Omega.shape[1]\n","\n","    if sizeOmega_C > number_nodes ** d - sizeOmega:\n","        raise ValueError(\"sizeOmega_C is too large to generate disjoint multi-indices\")\n","\n","    # Convertir Omega a un conjunto para verificaciones rápidas\n","    Omega = Omega.numpy() if isinstance(Omega, tf.Tensor) else Omega  # Convertir a numpy si es tensor\n","    Omega_set = set(map(tuple, Omega))\n","\n","    # Generar más índices de los necesarios para aumentar la probabilidad de encontrar suficientes disjuntos\n","    Omega_C = []\n","    candidates_per_batch = int(sizeOmega_C * 1.5)  # Generar 50% más candidatos por lote\n","    attempts = 0\n","    max_attempts = 10  # Número máximo de intentos para evitar bucles infinitos\n","\n","    while len(Omega_C) < sizeOmega_C and attempts < max_attempts:\n","        # Generar un lote de candidatos\n","        candidates = np.random.randint(0, number_nodes, size=(candidates_per_batch, d))\n","        # Filtrar candidatos que no estén en Omega_set ni en Omega_C\n","        for idx in candidates:\n","            idx_tuple = tuple(idx)\n","            if idx_tuple not in Omega_set and idx_tuple not in {tuple(x) for x in Omega_C}:\n","                Omega_C.append(idx)\n","                if len(Omega_C) >= sizeOmega_C:\n","                    break\n","        attempts += 1\n","\n","    if len(Omega_C) < sizeOmega_C:\n","        raise ValueError(f\"No se pudieron generar {sizeOmega_C} índices disjuntos después de {max_attempts} intentos\")\n","\n","    return np.array(Omega_C)\n","\n","# Funciones auxiliares necesarias\n","def inferir_dimension_entrada(f_vectorized, max_dimension=100):\n","    for d in range(1, max_dimension + 1):\n","        try:\n","            entrada_prueba = np.zeros((1, d))\n","            f_vectorized(entrada_prueba)\n","            return d\n","        except ValueError:\n","            pass\n","        except IndexError:\n","            pass\n","        except Exception:\n","            return None\n","    return None\n","\n","def adaptive_rank_strategy_Glau_fast(Omega, A_Omega, Omega_C, A_Omega_C, shape, max_rank, rank_initial, verbose, initial_guess=False, X_initial=None, max_iters=10, rho=1e-4):\n","    '''\n","    Implementa la estrategia de rango adaptativo rápida basada en el artículo de Steinlechner para la compleción tensorial.\n","    Permite inicializar el tensor X de dos maneras:\n","    - Si initial_guess=False (por defecto), X se inicializa como un tensor aleatorio deユTruncado de rango TT [1, rank_initial, ..., rank_initial, 1].\n","    - Si initial_guess=True, se debe proporcionar un tensor X_initial como entrada, que se usará como punto de partida.\n","\n","    Args:\n","        Omega (np.ndarray): Índices de las entradas observadas del tensor.\n","        A_Omega (np.ndarray): Valores de las entradas observadas del tensor.\n","        Omega_C (np.ndarray): Índices de las entradas observadas del tensor para validación.\n","        A_Omega_C (np.ndarray): Valores de las entradas observadas del tensor para validación.\n","        shape (tuple): Forma del tensor completo.\n","        max_rank (int): Rango TT máximo permitido.\n","        rank_initial (int): Rango TT inicial para la inicialización aleatoria.\n","        verbose (bool): Si True, imprime información detallada durante la ejecución.\n","        initial_guess (bool, opcional): Si True, se debe proporcionar X_initial. Si False, se inicializa X aleatoriamente. Por defecto es False.\n","        X_initial (t3f.TensorTrain, opcional): Tensor inicial en formato Tensor Train. Obligatorio si initial_guess=True.\n","        max_iters (int, opcional): Número máximo de iteraciones (giros de gradiente conjugado) en cada paso de la compleción Riemanniana. Por defecto es 10.\n","        rho (float, opcional): Umbral para aceptar el aumento de rango. Por defecto es 1e-4.\n","\n","    Returns:\n","        tuple: Una tupla que contiene:\n","            - X (t3f.TensorTrain): El tensor completado en formato Tensor Train.\n","            - errors (list): Lista de errores en el conjunto de validación (Omega_C) en cada paso de aceptación de aumento de rango.\n","    '''\n","    # Convertir entradas a tensores de TensorFlow\n","    Omega = tf.constant(Omega, dtype=tf.int32)\n","    Omega_C = tf.constant(Omega_C, dtype=tf.int32)\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    A_Omega_C = tf.constant(A_Omega_C, dtype=tf.float32)\n","\n","    # Número de dimensiones\n","    d = len(shape)\n","\n","    # Inicializar X según el valor de initial_guess\n","    if initial_guess:\n","        if X_initial is None:\n","            raise ValueError(\"Si initial_guess=True, se debe proporcionar X_initial.\")\n","        X = X_initial\n","    else:\n","        initial_tt_rank = [1] + [rank_initial] * (d - 1) + [1]\n","        X = t3f.random_tensor(shape, tt_rank=initial_tt_rank)\n","\n","    # Optimizar X inicial con Riemannian CG\n","    X = riemannian_tensor_completion(X, A_Omega, Omega, max_iters=max_iters, verbose=verbose)\n","\n","    # Calcular el error inicial en Omega_C\n","    X_Omega_C = t3f.gather_nd(X, Omega_C)\n","    norm_A_Omega_C = np.linalg.norm(A_Omega_C.numpy())\n","    error_X = np.linalg.norm(A_Omega_C.numpy() - X_Omega_C.numpy()) / norm_A_Omega_C\n","    if verbose:\n","        print(f\"Error inicial en Omega_C: {error_X:.6f}\")\n","\n","    # Lista para monitorear el error\n","    errors = [error_X]\n","\n","    # Inicializar locked y mu\n","    locked = 0\n","    mu = 1\n","\n","    # Bucle while con condiciones locked < d - 1 y max r_\\nu < r_max\n","    while locked < d - 1 and max(t3f.tt_ranks(X).numpy()[1:d]) < max_rank:\n","        tt_ranks = t3f.tt_ranks(X).numpy()\n","\n","        if tt_ranks[mu] < max_rank:\n","            # Aumentar el rango en la posición mu\n","            X_new = increase_tt_rank_mu(X, mu, noise_magnitude=1e-8)\n","\n","            # Optimizar X_new con Riemannian CG\n","            X_new = riemannian_tensor_completion(X_new, A_Omega, Omega, max_iters=max_iters, verbose=verbose)\n","            if verbose:\n","                print(f\"Aumento en mu={mu}: Rango TT de X_new: {t3f.tt_ranks(X_new).numpy()}\")\n","\n","            # Calcular el error de X_new en Omega_C\n","            X_new_Omega_C = t3f.gather_nd(X_new, Omega_C)\n","            error_X_new = np.linalg.norm(A_Omega_C.numpy() - X_new_Omega_C.numpy()) / norm_A_Omega_C\n","            if verbose:\n","                print(f\"Aumento en mu={mu}: error_X_new = {error_X_new:.6f}\")\n","\n","            # Criterio de aceptación\n","            if error_X_new - error_X > -rho:\n","                locked += 1\n","                if verbose:\n","                    print(f\"Aumento de rango rechazado para mu={mu}.\")\n","            else:\n","                X = X_new\n","                error_X = error_X_new\n","                errors.append(error_X)\n","                locked = 0\n","                if verbose:\n","                    print(f\"Aumento de rango aceptado para mu={mu}.\")\n","        else:\n","            locked += 1\n","            if verbose:\n","                print(f\"Rango en mu={mu} ya es max_rank.\")\n","\n","        # Actualizar mu cíclicamente\n","        mu = (mu % (d - 1)) + 1\n","\n","    if verbose:\n","        print(f\"Error final en Omega_C: {error_X:.6f}\")\n","    return X, errors\n","\n","def adaptive_sampling_strategy_1(f_vectorized, sizeOmega, sizeOmega_C, number_nodes, rank_initial, max_rank, p=0.2, tol_1=1e-4, tol_2=1e-8, max_iters=10, rho=1e-4, verbose=False):\n","    d = inferir_dimension_entrada(f_vectorized)\n","    n = number_nodes * np.ones(d, dtype=int)\n","    shape = tuple(n)\n","\n","    # Paso 1: Crear conjunto de prueba inicial Omega_C_new disjunto de Omega\n","    Omega = make_omega_set(number_nodes, sizeOmega, d)\n","    Omega_mapped = map_to_chebyshev_nodes(Omega, number_nodes)\n","    Omega_C_new = generate_disjoint_omega_c(Omega, sizeOmega_C, number_nodes)\n","    Omega_C_new_mapped = map_to_chebyshev_nodes(Omega_C_new, number_nodes)\n","\n","    # Generar valores evaluando la función en los puntos mapeados\n","    A_Omega = f_vectorized(Omega_mapped)\n","    A_Omega_C_new = f_vectorized(Omega_C_new_mapped)\n","\n","    # Convertir a tensores de TensorFlow\n","    Omega = tf.constant(Omega, dtype=tf.int32)\n","    Omega_C_new = tf.constant(Omega_C_new, dtype=tf.int32)\n","    A_Omega = tf.constant(A_Omega, dtype=tf.float32)\n","    A_Omega_C_new = tf.constant(A_Omega_C_new, dtype=tf.float32)\n","\n","    # Paso 2: Ejecutar Algorithm 1 para obtener X_c inicial con inicialización aleatoria\n","    X_c, _ = adaptive_rank_strategy_Glau_fast(\n","        Omega, A_Omega, Omega_C_new, A_Omega_C_new, shape, max_rank, rank_initial,\n","        verbose=verbose, initial_guess=False, max_iters=max_iters, rho=rho\n","    )\n","\n","    # Paso 3: Calcular error inicial en Omega_C_new\n","    X_Omega_C_new = t3f.gather_nd(X_c, Omega_C_new)\n","    err_new = np.linalg.norm(A_Omega_C_new.numpy() - X_Omega_C_new.numpy()) / np.linalg.norm(A_Omega_C_new.numpy())\n","    if verbose:\n","        print(f\"Iteración 0: |Omega| = {len(Omega)}, Error en Omega_C = {err_new:.6f}\")\n","\n","    # Paso 4: Bucle mientras |Omega| / size(A) < p\n","    iteration = 0\n","    while len(Omega) / np.prod(shape) < p:\n","        iteration += 1\n","        # Paso 5: Guardar error anterior\n","        err_old = err_new\n","\n","        # Paso 6: Aproximar X_c a rango (1, ..., 1)\n","        X_hat = t3f.round(X_c, max_tt_rank=rank_initial)\n","\n","        # Paso 7: Guardar Omega_C_old\n","        Omega_C_old = Omega_C_new\n","        A_Omega_C_old = A_Omega_C_new\n","\n","        # Paso 8: Crear nuevo Omega_C_new disjunto de Omega_C_old\n","        Omega_C_new = generate_disjoint_omega_c(Omega_C_old, sizeOmega_C, number_nodes)\n","        Omega_C_new_mapped = map_to_chebyshev_nodes(Omega_C_new, number_nodes)\n","        A_Omega_C_new = f_vectorized(Omega_C_new_mapped)\n","\n","        # Convertir nuevos conjuntos a tensores\n","        Omega_C_new = tf.constant(Omega_C_new, dtype=tf.int32)\n","        A_Omega_C_new = tf.constant(A_Omega_C_new, dtype=tf.float32)\n","\n","        # Paso 9: Actualizar Omega con Omega_C_old\n","        Omega = tf.concat([Omega, Omega_C_old], axis=0)\n","        A_Omega = tf.concat([A_Omega, A_Omega_C_old], axis=0)\n","\n","        # Añadir print aquí para mostrar el tamaño de Omega\n","        print(f\"Iteración {iteration}: Tamaño de Omega = {tf.shape(Omega)[0].numpy()}\")\n","\n","        # Paso 10: Ejecutar Algorithm 1 con X_hat como punto inicial\n","        X_c, _ = adaptive_rank_strategy_Glau_fast(\n","            Omega, A_Omega, Omega_C_new, A_Omega_C_new, shape, max_rank, rank_initial,\n","            verbose=verbose, initial_guess=True, X_initial=X_hat, max_iters=max_iters, rho=rho\n","        )\n","\n","        # Paso 11: Calcular nuevo error en Omega_C_new\n","        X_Omega_C_new = t3f.gather_nd(X_c, Omega_C_new)\n","        err_new = np.linalg.norm(A_Omega_C_new.numpy() - X_Omega_C_new.numpy()) / np.linalg.norm(A_Omega_C_new.numpy())\n","\n","        # Paso 12: Verificar criterios de parada\n","        tt_ranks = t3f.tt_ranks(X_c)\n","        rank_max_reached = any(r >= max_rank for r in tt_ranks[1:-1])\n","\n","        if verbose:\n","            print(f\"Iteración {iteration}: |Omega| = {len(Omega)}, Error en Omega_C = {err_new:.6f}, Rango TT = {tt_ranks.numpy()}\")\n","\n","        if (err_new < tol_1 or\n","            abs(err_new - err_old) < tol_2 or\n","            rank_max_reached):\n","            break\n","\n","    # Paso 16: Asignar tensor final\n","    X = X_c\n","\n","    return X"]},{"cell_type":"markdown","id":"4b6c178e","metadata":{"id":"4b6c178e"},"source":["---"]},{"cell_type":"markdown","id":"2e68b39b","metadata":{"id":"2e68b39b"},"source":["# Ideas for improvement"]},{"cell_type":"markdown","id":"90d54a21","metadata":{"id":"90d54a21"},"source":["Maybe implement a very basic tensor completion for the initial guess of the algorithm, instead of starting with a random tensor."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["bbcdbb8d","6c3e5fcd","a5b382ec","3c5fc744","53fee4f4"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}
